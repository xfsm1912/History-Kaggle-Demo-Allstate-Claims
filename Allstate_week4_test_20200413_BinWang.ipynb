{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Allstate_week4_test_20200413_BinWang.ipynb","provenance":[{"file_id":"10HuwxYb6mvW_Li4fEH3cbTkNFKd666Rx","timestamp":1586834260419}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMwHCFt1SFoWvhzzGLpvix4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5uIXd1GVOugV","colab_type":"code","colab":{}},"source":["import xgboost as xgb\n","import pandas as pd\n","# from sklearn import preprocessing, pipeline, metrics, grid_search, cross_validation\n","from sklearn import preprocessing, pipeline, metrics\n","from sklearn.model_selection import GridSearchCV, GroupKFold, cross_validate, cross_val_score\n","import time\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from sklearn.metrics import mean_absolute_error\n","\n","from scipy import sparse\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fyFMPJkUQhk-","colab_type":"text"},"source":["grid_search: GridSearchCV \\\\\n","cross_validation: cross_validate"]},{"cell_type":"code","metadata":{"id":"sMba70kCO8QH","colab_type":"code","colab":{}},"source":["def log_mae(labels,preds,lift=200):\n","    return mean_absolute_error(np.exp(labels)-lift, np.exp(preds)-lift)\n","\n","def logregobj(labels, preds):\n","    con = 2\n","    x =preds-labels\n","    grad =con*x / (np.abs(x)+con)\n","    hess =con**2 / (np.abs(x)+con)**2\n","    return grad, hess \n","\n","\n","log_mae_scorer = metrics.make_scorer(log_mae, greater_is_better = False)\n","\n","def search_model(train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n","    ##Grid Search for the best model\n","    model = GridSearchCV(estimator  = est,\n","                                     param_grid = param_grid,\n","                                     scoring    = log_mae_scorer,\n","                                     verbose    = 10,\n","                                     n_jobs  = n_jobs,\n","                                     iid        = True,\n","                                     refit    = refit,\n","                                     cv      = cv)\n","    # Fit Grid Search Model\n","    model.fit(train_x, train_y)\n","    print(\"params:\\n\")\n","    print(model.cv_results_.__getitem__('params'))\n","    print(\"mean test scores:\\n\")\n","    print(model.cv_results_.__getitem__('mean_test_score'))\n","    print(\"std test scores:\\n\")\n","    print(model.cv_results_.__getitem__('std_test_score'))\n","    print(\"Best score: %0.3f\" % model.best_score_)\n","    print(\"Best parameters set:\", model.best_params_)\n","    # print(\"Scores:\", model.grid_scores_)\n","    print(\"**********************************************\")\n","    \n","    return model\n","\n","def xg_eval_mae(yhat, dtrain, lift=200):\n","    y = dtrain.get_label()\n","    return 'mae', mean_absolute_error(np.exp(y)-lift, np.exp(yhat)-lift)\n","\n","def xgb_logregobj(preds, dtrain):\n","    con = 2\n","    labels = dtrain.get_label()\n","    x =preds-labels\n","    grad =con*x / (np.abs(x)+con)\n","    hess =con**2 / (np.abs(x)+con)**2\n","    return grad, hess\n","\n","\n","def search_model_mae (train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n","##Grid Search for the best model\n","    model = GridSearchCV(estimator  = est,\n","                          param_grid = param_grid,\n","                          scoring    = 'neg_mean_absolute_error',\n","                          verbose    = 10,\n","                          n_jobs  = n_jobs,\n","                          iid        = True,\n","                          refit    = refit,\n","                          cv      = cv)\n","    # Fit Grid Search Model\n","    model.fit(train_x, train_y)\n","    print(\"Best score: %0.3f\" % model.best_score_)\n","    print(\"Best parameters set:\", model.best_params_)\n","    # print(\"Scores:\", model.grid_scores_)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-_fwxo6ck9q","colab_type":"text"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"TYfH1lXacug8","colab_type":"code","outputId":"bda7248c-a7ee-43f8-c436-80cd6b356220","executionInfo":{"status":"ok","timestamp":1585923996861,"user_tz":240,"elapsed":22161,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7DV33cCjculk","colab_type":"code","colab":{}},"source":["# !cp -r /content/drive/My\\ Drive/Kaggle_Allstate/data/train.csv /home/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqN3Yju0dbyw","colab_type":"code","colab":{}},"source":["# !cp -r /content/drive/My\\ Drive/Kaggle_Allstate/data/test.csv /home/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvo1O_Vucjgm","colab_type":"code","outputId":"f894bcaa-c968-4807-bf6f-c9a410f362c9","executionInfo":{"status":"ok","timestamp":1585924008810,"user_tz":240,"elapsed":5777,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Load data\n","start = time.time() \n","train_data = pd.read_csv('/home/train.csv')\n","train_size=train_data.shape[0]\n","print (\"Loading train data finished in %0.3fs\" % (time.time() - start))        \n","\n","test_data = pd.read_csv('/home/test.csv')\n","print (\"Loading test data finished in %0.3fs\" % (time.time() - start))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading train data finished in 3.302s\n","Loading test data finished in 5.206s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"64YxhaBucjvU","colab_type":"code","outputId":"6346f786-01d0-4e0e-be76-fb7df98349a5","executionInfo":{"status":"ok","timestamp":1585924010390,"user_tz":240,"elapsed":471,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":253}},"source":["train_data.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>cat1</th>\n","      <th>cat2</th>\n","      <th>cat3</th>\n","      <th>cat4</th>\n","      <th>cat5</th>\n","      <th>cat6</th>\n","      <th>cat7</th>\n","      <th>cat8</th>\n","      <th>cat9</th>\n","      <th>cat10</th>\n","      <th>cat11</th>\n","      <th>cat12</th>\n","      <th>cat13</th>\n","      <th>cat14</th>\n","      <th>cat15</th>\n","      <th>cat16</th>\n","      <th>cat17</th>\n","      <th>cat18</th>\n","      <th>cat19</th>\n","      <th>cat20</th>\n","      <th>cat21</th>\n","      <th>cat22</th>\n","      <th>cat23</th>\n","      <th>cat24</th>\n","      <th>cat25</th>\n","      <th>cat26</th>\n","      <th>cat27</th>\n","      <th>cat28</th>\n","      <th>cat29</th>\n","      <th>cat30</th>\n","      <th>cat31</th>\n","      <th>cat32</th>\n","      <th>cat33</th>\n","      <th>cat34</th>\n","      <th>cat35</th>\n","      <th>cat36</th>\n","      <th>cat37</th>\n","      <th>cat38</th>\n","      <th>cat39</th>\n","      <th>...</th>\n","      <th>cat92</th>\n","      <th>cat93</th>\n","      <th>cat94</th>\n","      <th>cat95</th>\n","      <th>cat96</th>\n","      <th>cat97</th>\n","      <th>cat98</th>\n","      <th>cat99</th>\n","      <th>cat100</th>\n","      <th>cat101</th>\n","      <th>cat102</th>\n","      <th>cat103</th>\n","      <th>cat104</th>\n","      <th>cat105</th>\n","      <th>cat106</th>\n","      <th>cat107</th>\n","      <th>cat108</th>\n","      <th>cat109</th>\n","      <th>cat110</th>\n","      <th>cat111</th>\n","      <th>cat112</th>\n","      <th>cat113</th>\n","      <th>cat114</th>\n","      <th>cat115</th>\n","      <th>cat116</th>\n","      <th>cont1</th>\n","      <th>cont2</th>\n","      <th>cont3</th>\n","      <th>cont4</th>\n","      <th>cont5</th>\n","      <th>cont6</th>\n","      <th>cont7</th>\n","      <th>cont8</th>\n","      <th>cont9</th>\n","      <th>cont10</th>\n","      <th>cont11</th>\n","      <th>cont12</th>\n","      <th>cont13</th>\n","      <th>cont14</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>T</td>\n","      <td>B</td>\n","      <td>G</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>I</td>\n","      <td>E</td>\n","      <td>G</td>\n","      <td>J</td>\n","      <td>G</td>\n","      <td>BU</td>\n","      <td>BC</td>\n","      <td>C</td>\n","      <td>AS</td>\n","      <td>S</td>\n","      <td>A</td>\n","      <td>O</td>\n","      <td>LB</td>\n","      <td>0.726300</td>\n","      <td>0.245921</td>\n","      <td>0.187583</td>\n","      <td>0.789639</td>\n","      <td>0.310061</td>\n","      <td>0.718367</td>\n","      <td>0.335060</td>\n","      <td>0.30260</td>\n","      <td>0.67135</td>\n","      <td>0.83510</td>\n","      <td>0.569745</td>\n","      <td>0.594646</td>\n","      <td>0.822493</td>\n","      <td>0.714843</td>\n","      <td>2213.18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>T</td>\n","      <td>L</td>\n","      <td>F</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>I</td>\n","      <td>K</td>\n","      <td>K</td>\n","      <td>BI</td>\n","      <td>CQ</td>\n","      <td>A</td>\n","      <td>AV</td>\n","      <td>BM</td>\n","      <td>A</td>\n","      <td>O</td>\n","      <td>DP</td>\n","      <td>0.330514</td>\n","      <td>0.737068</td>\n","      <td>0.592681</td>\n","      <td>0.614134</td>\n","      <td>0.885834</td>\n","      <td>0.438917</td>\n","      <td>0.436585</td>\n","      <td>0.60087</td>\n","      <td>0.35127</td>\n","      <td>0.43919</td>\n","      <td>0.338312</td>\n","      <td>0.366307</td>\n","      <td>0.611431</td>\n","      <td>0.304496</td>\n","      <td>1283.60</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>L</td>\n","      <td>O</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>E</td>\n","      <td>F</td>\n","      <td>H</td>\n","      <td>F</td>\n","      <td>A</td>\n","      <td>AB</td>\n","      <td>DK</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>AF</td>\n","      <td>A</td>\n","      <td>I</td>\n","      <td>GK</td>\n","      <td>0.261841</td>\n","      <td>0.358319</td>\n","      <td>0.484196</td>\n","      <td>0.236924</td>\n","      <td>0.397069</td>\n","      <td>0.289648</td>\n","      <td>0.315545</td>\n","      <td>0.27320</td>\n","      <td>0.26076</td>\n","      <td>0.32446</td>\n","      <td>0.381398</td>\n","      <td>0.373424</td>\n","      <td>0.195709</td>\n","      <td>0.774425</td>\n","      <td>3005.09</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>D</td>\n","      <td>C</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>D</td>\n","      <td>T</td>\n","      <td>I</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>I</td>\n","      <td>K</td>\n","      <td>K</td>\n","      <td>BI</td>\n","      <td>CS</td>\n","      <td>C</td>\n","      <td>N</td>\n","      <td>AE</td>\n","      <td>A</td>\n","      <td>O</td>\n","      <td>DJ</td>\n","      <td>0.321594</td>\n","      <td>0.555782</td>\n","      <td>0.527991</td>\n","      <td>0.373816</td>\n","      <td>0.422268</td>\n","      <td>0.440945</td>\n","      <td>0.391128</td>\n","      <td>0.31796</td>\n","      <td>0.32128</td>\n","      <td>0.44467</td>\n","      <td>0.327915</td>\n","      <td>0.321570</td>\n","      <td>0.605077</td>\n","      <td>0.602642</td>\n","      <td>939.85</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>...</td>\n","      <td>H</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>E</td>\n","      <td>A</td>\n","      <td>P</td>\n","      <td>F</td>\n","      <td>J</td>\n","      <td>A</td>\n","      <td>A</td>\n","      <td>D</td>\n","      <td>E</td>\n","      <td>K</td>\n","      <td>G</td>\n","      <td>B</td>\n","      <td>H</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>Y</td>\n","      <td>BM</td>\n","      <td>A</td>\n","      <td>K</td>\n","      <td>CK</td>\n","      <td>0.273204</td>\n","      <td>0.159990</td>\n","      <td>0.527991</td>\n","      <td>0.473202</td>\n","      <td>0.704268</td>\n","      <td>0.178193</td>\n","      <td>0.247408</td>\n","      <td>0.24564</td>\n","      <td>0.22089</td>\n","      <td>0.21230</td>\n","      <td>0.204687</td>\n","      <td>0.202213</td>\n","      <td>0.246011</td>\n","      <td>0.432606</td>\n","      <td>2763.85</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 132 columns</p>\n","</div>"],"text/plain":["   id cat1 cat2 cat3 cat4  ...    cont11    cont12    cont13    cont14     loss\n","0   1    A    B    A    B  ...  0.569745  0.594646  0.822493  0.714843  2213.18\n","1   2    A    B    A    A  ...  0.338312  0.366307  0.611431  0.304496  1283.60\n","2   5    A    B    A    A  ...  0.381398  0.373424  0.195709  0.774425  3005.09\n","3  10    B    B    A    B  ...  0.327915  0.321570  0.605077  0.602642   939.85\n","4  11    A    B    A    B  ...  0.204687  0.202213  0.246011  0.432606  2763.85\n","\n","[5 rows x 132 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"CJiTy5Yvd3IS","colab_type":"text"},"source":["## Merge train and test"]},{"cell_type":"code","metadata":{"id":"8wbC_reMcj-e","colab_type":"code","outputId":"dc0413f2-8ad3-40b0-e5ce-073997a2f1b0","executionInfo":{"status":"ok","timestamp":1585924013811,"user_tz":240,"elapsed":713,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["full_data=pd.concat([train_data\n","                       ,test_data])\n","del( train_data, test_data)\n","print (\"Full Data set created.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Full Data set created.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SWMZPzEAd5Ty","colab_type":"text"},"source":["## Group features"]},{"cell_type":"code","metadata":{"id":"KvO4Swrtcjmw","colab_type":"code","outputId":"932bc79d-4df0-4c5c-92c3-419e033495ff","executionInfo":{"status":"ok","timestamp":1585924015982,"user_tz":240,"elapsed":442,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["data_types = full_data.dtypes  \n","cat_cols = list(data_types[data_types=='object'].index)\n","num_cols = list(data_types[data_types=='int64'].index) + list(data_types[data_types=='float64'].index)\n","\n","id_col = 'id'\n","target_col = 'loss'\n","num_cols.remove('id')\n","num_cols.remove('loss')\n","\n","print (\"Categorical features:\", cat_cols)\n","print ( \"Numerica features:\", num_cols)\n","print ( \"ID: %s, target: %s\" %( id_col, target_col))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Categorical features: ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21', 'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28', 'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35', 'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', 'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63', 'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116']\n","Numerica features: ['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']\n","ID: id, target: loss\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J0Qggc_pd9WD","colab_type":"code","outputId":"a0f52992-5142-4a1e-83c9-4dddce76305b","executionInfo":{"status":"ok","timestamp":1585924037217,"user_tz":240,"elapsed":19075,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["LBL = preprocessing.LabelEncoder()\n","start=time.time()\n","for cat_col in cat_cols:\n","#     print (\"Factorize feature %s\" % (cat))\n","    full_data[cat_col] = LBL.fit_transform(full_data[cat_col])\n","print ('Label enconding finished in %f seconds' % (time.time()-start))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Label enconding finished in 18.787762 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aSPNZ_0Id9e-","colab_type":"code","outputId":"4e328494-a44d-4480-f46e-034419035bc8","executionInfo":{"status":"ok","timestamp":1585924100891,"user_tz":240,"elapsed":3331,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["OHE = preprocessing.OneHotEncoder(sparse=True)\n","start=time.time()\n","full_data_sparse=OHE.fit_transform(full_data[cat_cols])\n","print ('One-hot-encoding finished in %f seconds' % (time.time()-start))\n","\n","print (full_data_sparse.shape)\n","\n","## it should be (313864, 1176)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["One-hot-encoding finished in 2.965760 seconds\n","(313864, 1176)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zn1E4gxLeOcN","colab_type":"code","outputId":"94a08d7a-2c54-4bf2-8884-b6723e11bda8","executionInfo":{"status":"ok","timestamp":1585924102832,"user_tz":240,"elapsed":308,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["from scipy.stats import skew, boxcox\n","skewed_cols = full_data[num_cols].apply(lambda x: skew(x.dropna()))\n","print (skewed_cols.sort_values())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cont2    -0.311146\n","cont3    -0.007023\n","cont14    0.250673\n","cont11    0.281139\n","cont12    0.291997\n","cont10    0.352116\n","cont13    0.376138\n","cont4     0.417559\n","cont6     0.458413\n","cont1     0.513205\n","cont8     0.673237\n","cont5     0.679610\n","cont7     0.825889\n","cont9     1.067247\n","dtype: float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iGxfoG6feOlY","colab_type":"code","colab":{}},"source":["skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n","for skewed_col in skewed_cols:\n","    full_data[skewed_col], lam = boxcox(full_data[skewed_col] + 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qmbWjHs1eUNz","colab_type":"code","colab":{}},"source":["SSL = preprocessing.StandardScaler()\n","# for num_col in num_cols:\n","#     full_data[num_col] = full_data[num_col].values.reshape(-1, 1)\n","#     full_data[num_col] = SSL.fit_transform(full_data[num_col])\n","\n","full_data[num_cols] = SSL.fit_transform(full_data[num_cols])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pDtydEYeUe7","colab_type":"code","outputId":"0fb84506-045a-4a5a-bab3-2439d547f5b5","executionInfo":{"status":"ok","timestamp":1585924129200,"user_tz":240,"elapsed":1710,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from scipy import sparse\n","full_data_sparse = sparse.hstack((full_data_sparse,full_data[num_cols])).tocsr()\n","print (full_data_sparse.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(313864, 1190)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OCu3WPNEeUpz","colab_type":"code","colab":{}},"source":["shift = 200\n","full_cols = cat_cols + num_cols\n","train_x = full_data_sparse[:train_size]\n","test_x = full_data_sparse[train_size:]\n","train_y = np.log(full_data[:train_size].loss.values + 200)\n","ID = full_data.id[:train_size].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xGtwn7TeU1R","colab_type":"code","colab":{}},"source":["# # Initialize data\n","# lift = 200\n","\n","# full_cols = num_cols + cat_cols\n","# train_x = full_data[full_cols][:train_size].values\n","# test_x = full_data[full_cols][train_size:].values\n","# train_y = np.log(full_data[:train_size].loss.values + lift)\n","# ID = full_data.id[:train_size].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JCxuj3-3lJTS","colab_type":"code","outputId":"ecf73ab5-73eb-42ee-cdc9-83e9fa35879b","executionInfo":{"status":"ok","timestamp":1585924132732,"user_tz":240,"elapsed":282,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(train_x.shape)\n","print(test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(188318, 1190)\n","(125546, 1190)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fVtGeMczlg6S","colab_type":"text"},"source":["## gridresearch model"]},{"cell_type":"code","metadata":{"id":"NLvGpxO6lJ_P","colab_type":"code","colab":{}},"source":["import lightgbm as lgb\n","from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ndNcZ1l0lriG","colab_type":"code","outputId":"7c291736-a45d-4e08-f2f9-663ffc4272f2","executionInfo":{"status":"error","timestamp":1585193724320,"user_tz":240,"elapsed":544425,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# time consuming, use gpu to tune\n","param_grid = {'objective':[logregobj],\n","              'learning_rate':[0.01, 0.02, 0.04, 0.06, 0.08],\n","              'n_estimators':[1500],\n","              'max_depth': [9],\n","              'min_child_weight':[50],\n","              'subsample': [0.78],\n","              'colsample_bytree':[0.67],\n","              'gamma':[0.9],\n","              'nthread': [-1],\n","              'seed' : [1234]}\n","\n","model = search_model(train_x,\n","                     train_y,\n","                     xgb.XGBRegressor(),\n","                     param_grid,\n","                     n_jobs = 1,\n","                     cv = 4,\n","                     refit = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting 4 folds for each of 4 candidates, totalling 16 fits\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["[00:51:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1136.103, total= 9.8min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.8min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:01:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1138.455, total= 9.5min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 19.3min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:10:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1136.343, total= 9.3min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 28.6min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:20:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1134.285, total= 9.3min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 37.9min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:29:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1138.003, total= 9.2min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 47.1min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:38:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1140.889, total= 9.2min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 56.2min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:47:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1139.231, total= 9.2min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 65.4min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[01:56:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.04, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1136.665, total= 9.4min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 74.8min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[02:06:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1139.839, total= 9.2min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 84.0min remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[02:15:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1144.969, total= 9.2min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n","[02:24:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1143.111, total= 9.5min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n","[02:34:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.06, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1141.239, total= 9.5min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n","[02:43:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1147.522, total= 9.6min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n","[02:53:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1151.760, total= 9.8min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n","[03:03:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1147.431, total= 9.5min\n","[CV] colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78 \n","[03:12:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[CV]  colsample_bytree=0.67, gamma=0.9, learning_rate=0.08, max_depth=9, min_child_weight=50, n_estimators=1500, nthread=-1, objective=<function logregobj at 0x7f7626c23f28>, seed=1234, subsample=0.78, score=-1146.045, total= 9.7min\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 150.9min finished\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n","  \"removed in 0.24.\", FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["[03:22:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","params:\n","\n","[{'colsample_bytree': 0.67, 'gamma': 0.9, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 50, 'n_estimators': 1500, 'nthread': -1, 'objective': <function logregobj at 0x7f7626c23f28>, 'seed': 1234, 'subsample': 0.78}, {'colsample_bytree': 0.67, 'gamma': 0.9, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 50, 'n_estimators': 1500, 'nthread': -1, 'objective': <function logregobj at 0x7f7626c23f28>, 'seed': 1234, 'subsample': 0.78}, {'colsample_bytree': 0.67, 'gamma': 0.9, 'learning_rate': 0.06, 'max_depth': 9, 'min_child_weight': 50, 'n_estimators': 1500, 'nthread': -1, 'objective': <function logregobj at 0x7f7626c23f28>, 'seed': 1234, 'subsample': 0.78}, {'colsample_bytree': 0.67, 'gamma': 0.9, 'learning_rate': 0.08, 'max_depth': 9, 'min_child_weight': 50, 'n_estimators': 1500, 'nthread': -1, 'objective': <function logregobj at 0x7f7626c23f28>, 'seed': 1234, 'subsample': 0.78}]\n","mean test scores:\n","\n","[-1136.29651101 -1138.69704131 -1142.28933397 -1148.18924146]\n","std test scores:\n","\n","[1.47833498 1.5575086  1.93411403 2.14286427]\n","Best score: -1136.297\n","Best parameters set: {'colsample_bytree': 0.67, 'gamma': 0.9, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 50, 'n_estimators': 1500, 'nthread': -1, 'objective': <function logregobj at 0x7f7626c23f28>, 'seed': 1234, 'subsample': 0.78}\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-a00d1aaea993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                      \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                      refit = True)\n\u001b[0m","\u001b[0;32m<ipython-input-26-be28f90e107d>\u001b[0m in \u001b[0;36msearch_model\u001b[0;34m(train_x, train_y, est, param_grid, n_jobs, cv, refit)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Scores:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**********************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"]}]},{"cell_type":"code","metadata":{"id":"o3M94S-slruy","colab_type":"code","outputId":"96e458e5-d082-44ae-dabb-36b8d228dd22","executionInfo":{"status":"ok","timestamp":1585183239923,"user_tz":240,"elapsed":782965,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["\n","# here just an example, please use the optimal parameters from last gridsearch cell\n","rgr = xgb.XGBRegressor(seed = 1234, \n","                       learning_rate = 0.02, # smaller, better results, more time\n","                       n_estimators = 1500, # Number of boosted trees to fit. \n","                       max_depth=9, # the maximum depth of a tree\n","                       min_child_weight=50,\n","                       colsample_bytree=0.67, # the fraction of columns to be randomly samples for each tree\n","                       subsample=0.78, # the fraction of observations to be randomly samples for each tree\n","                       gamma=0.9, # Minimum loss reduction required to make a further partition on a leaf node of the tree, \n","                       # the larger, the more conservative \n","                       nthread = -1, # Number of parallel threads used to run xgboost.\n","                       silent = False # Whether to print messages while running boosting.\n","                      )\n","rgr.fit(train_x, train_y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[00:27:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","             colsample_bynode=1, colsample_bytree=0.67, gamma=0.9,\n","             importance_type='gain', learning_rate=0.02, max_delta_step=0,\n","             max_depth=9, min_child_weight=50, missing=None, n_estimators=1500,\n","             n_jobs=1, nthread=-1, objective='reg:linear', random_state=0,\n","             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1234,\n","             silent=False, subsample=0.78, verbosity=1)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"Cr66Y4yUlr9m","colab_type":"code","outputId":"f9260bf1-c70b-4539-e0df-438c6b30d3fa","executionInfo":{"status":"ok","timestamp":1585183475144,"user_tz":240,"elapsed":14245,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pred_y = np.exp(rgr.predict(test_x)) - 200\n","\n","results = pd.DataFrame()\n","results['id'] = full_data[train_size:].id\n","results['loss'] = pred_y\n","results.to_csv(\"/home/sub.csv\", index=False)\n","print (\"Submission created.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Submission created.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"px9uzkuglsqX","colab_type":"code","outputId":"2ff28793-eb62-40af-e63c-82ce0e9d74aa","executionInfo":{"status":"ok","timestamp":1585195466222,"user_tz":240,"elapsed":3294,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["plt.bar(range(len(rgr.feature_importances_)), rgr.feature_importances_)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jK75uQHpltOS","colab_type":"code","outputId":"b4f5258b-c8db-420c-ba55-28967aedbeec","executionInfo":{"status":"ok","timestamp":1585183614813,"user_tz":240,"elapsed":721,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":312}},"source":["xgb.plot_importance(rgr,max_num_features=5,importance_type='weight')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f7626e4f278>"]},"metadata":{"tags":[]},"execution_count":34},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqICIiEgkKiAiIhKJCoiIiETy/wFM4fKocYqDhwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"asVkrV_lltZn","colab_type":"code","outputId":"4bd868b9-63bc-45af-8665-de55d2ad035d","executionInfo":{"status":"ok","timestamp":1585196003506,"user_tz":240,"elapsed":1000,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.argsort(rgr.feature_importances_)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 594,  467,  471, ..., 1047, 1051, 1053])"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"M7t-dewAC4z3","colab_type":"text"},"source":["## Parameter tuning\n","### XGBoost manual greedy tuning \n","\n","xgb max_depth must be >=0 \n"]},{"cell_type":"code","metadata":{"id":"HzU7YBQZO6lE","colab_type":"code","outputId":"f451eb6e-db83-4c8b-e077-73ab74ffcc68","executionInfo":{"status":"ok","timestamp":1585924230588,"user_tz":240,"elapsed":317,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["from sklearn.model_selection import KFold,StratifiedKFold\n","import copy\n","kfolds = 5\n","random_state = 42\n","\n","# skf = StratifiedKFold(n_splits=kfolds, shuffle=True, random_state=random_state)\n","skf = KFold(n_splits=kfolds, random_state=1234)\n","skf_ids = list(skf.split(train_y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"U9ePKHTIXy6a","colab_type":"text"},"source":["lgb vs xgb:\n","bagging_freq = Not have this feature \\\\\n","num_leaves = max_leaves \\\\\n","max_depth = max_depth \\\\\n","min_gain_to_split = gamma \\\\\n","feature_fraction = colsample_bytree \\\\\n","bagging_fraction = subsample \\\\\n","min_sum_hessian_in_leaf = min_child_weight \\\\\n","lambda_l2 = lambda \\\\\n","lambda_l1 = alpha \\\\"]},{"cell_type":"code","metadata":{"id":"Ul1CIglBC4GT","colab_type":"code","colab":{}},"source":["default_xgb_params = {}\n","default_xgb_params[\"learning_rate\"] = 0.05\n","default_xgb_params[\"metrics\"] = 'rmse'\n","default_xgb_params[\"subsample\"] = 1\n","default_xgb_params[\"seed\"] = 1234\n","default_xgb_params[\"objective\"] = 'reg:squarederror'\n","\n","params_xgb_space = {}\n","params_xgb_space['max_leaves'] = [3, 7, 15, 31, 63, 127, 255] # the performance of =3 is equalt to others \n","params_xgb_space['max_depth'] = [3 ,4 ,5 ,6 ,7 ,8] \n","params_xgb_space['gamma'] = [0, 0.1, 0.3, 1, 1.5, 2, 3]\n","params_xgb_space['colsample_bytree'] = [0.1, 0.3, 0.5, 0.7, 0.9]\n","params_xgb_space['subsample'] = [0.2, 0.4, 0.6, 0.8, 1]\n","params_xgb_space['min_child_weight'] = [1, 5, 10, 30, 100]\n","params_xgb_space['lambda'] = [0, 0.01, 0.1, 1, 10, 100]\n","params_xgb_space['alpha'] = [0, 0.01, 0.1, 1, 10, 100]\n","# params_xgb_space['max_leaves'] = [3]\n","# params_xgb_space['max_depth'] = [8] \n","# params_xgb_space['gamma'] = [1]\n","# params_xgb_space['colsample_bytree'] = [0.1]\n","# params_xgb_space['subsample'] = [1]\n","# params_xgb_space['min_child_weight'] = [100]\n","# params_xgb_space['lambda'] = [100]\n","# params_xgb_space['alpha'] = [0, 0.01, 0.1, 1, 10, 100]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"753WdFV6DJjJ","colab_type":"code","outputId":"fbe91ae8-f3e1-49f7-f09a-9db399738308","executionInfo":{"status":"ok","timestamp":1585371454148,"user_tz":240,"elapsed":13979635,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":717}},"source":["greater_is_better = False\n","\n","best_xgb_params = copy.copy(default_xgb_params)\n","\n","for p in params_xgb_space:\n","    print (\"\\n Tuning parameter %s in %s\" % (p, params_xgb_space[p]))\n","\n","    params = best_xgb_params\n","    scores = []    \n","    for v in params_xgb_space[p]:\n","        print ('\\n    %s: %s' % (p, v), end=\"\\n\")\n","        params[p] = v\n","        xgb_cv = xgb.cv(params,\n","                        xgb.DMatrix(train_x,\n","                                    label=train_y\n","                                    ),\n","                        num_boost_round=100000,\n","                        nfold=kfolds,\n","                        folds=list(skf.split(train_y)),\n","                        stratified=False,\n","                        early_stopping_rounds=50,\n","                        verbose_eval=500)\n","\n","        best_xgb_score = min(xgb_cv['test-rmse-mean'])\n","        best_xgb_iteration = len(xgb_cv['test-rmse-mean'])\n","        print (', best_score: %f, best_iteration: %d' % (best_xgb_score, best_xgb_iteration))\n","        scores.append([v, best_xgb_score])\n","    # best param value in the space\n","    best_param_value = sorted(scores, key=lambda x:x[1],reverse=greater_is_better)[0][0]\n","    best_param_score = sorted(scores, key=lambda x:x[1],reverse=greater_is_better)[0][1]\n","    best_xgb_params[p] = best_param_value\n","    print (\"Best %s is %s with a score of %f\" %(p, best_param_value, best_param_score))\n","\n","print ('\\n Best manually tuned parameters:', best_xgb_params)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Tuning parameter alpha in [0, 0.01, 0.1, 1, 10, 100]\n","\n","    alpha: 0\n","[0]\ttrain-rmse:6.97191+0.000379767\ttest-rmse:6.97192+0.00170671\n","[500]\ttrain-rmse:0.454982+0.000391616\ttest-rmse:0.479481+0.00195369\n","[1000]\ttrain-rmse:0.442383+0.000359705\ttest-rmse:0.478398+0.00196716\n",", best_score: 0.478335, best_iteration: 1070\n","\n","    alpha: 0.01\n","[0]\ttrain-rmse:6.97191+0.000379767\ttest-rmse:6.97192+0.00170693\n","[500]\ttrain-rmse:0.454993+0.000481595\ttest-rmse:0.479482+0.00198249\n","[1000]\ttrain-rmse:0.442441+0.000496072\ttest-rmse:0.478491+0.00209966\n",", best_score: 0.478402, best_iteration: 1135\n","\n","    alpha: 0.1\n","[0]\ttrain-rmse:6.97191+0.000379977\ttest-rmse:6.97192+0.00170674\n","[500]\ttrain-rmse:0.454785+0.000298783\ttest-rmse:0.479572+0.00204853\n","[1000]\ttrain-rmse:0.441658+0.000402947\ttest-rmse:0.478523+0.00211454\n",", best_score: 0.478359, best_iteration: 1383\n","\n","    alpha: 1\n","[0]\ttrain-rmse:6.97192+0.000379352\ttest-rmse:6.97194+0.00171107\n","[500]\ttrain-rmse:0.455127+0.000469172\ttest-rmse:0.479181+0.00186617\n","[1000]\ttrain-rmse:0.439363+0.000232278\ttest-rmse:0.477738+0.00198273\n",", best_score: 0.477585, best_iteration: 1178\n","\n","    alpha: 10\n","[0]\ttrain-rmse:6.97201+0.000378521\ttest-rmse:6.97202+0.0016951\n","[500]\ttrain-rmse:0.463542+0.000574249\ttest-rmse:0.479049+0.00199016\n","[1000]\ttrain-rmse:0.450234+0.000450678\ttest-rmse:0.476699+0.0020447\n",", best_score: 0.476371, best_iteration: 1286\n","\n","    alpha: 100\n","[0]\ttrain-rmse:6.97233+0.00037422\ttest-rmse:6.97234+0.00171285\n","[500]\ttrain-rmse:0.47636+0.00054652\ttest-rmse:0.483031+0.00188349\n",", best_score: 0.481939, best_iteration: 651\n","Best alpha is 10 with a score of 0.476371\n","\n"," Best manually tuned parameters: {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'alpha': 10}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2vl3E2s5DJ_d","colab_type":"code","colab":{}},"source":["best_xgb_params = copy.copy(default_xgb_params)\n","# filled up with the best tuned parameters from last cell\n","best_xgb_params['max_leaves'] = 3\n","best_xgb_params['max_depth'] = 8\n","best_xgb_params['gamma'] = 1\n","best_xgb_params['colsample_bytree'] = 0.1\n","best_xgb_params['subsample'] = 1\n","best_xgb_params['min_child_weight'] = 100\n","best_xgb_params['lambda'] = 100\n","best_xgb_params['alpha'] = 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqujTw_IDKPx","colab_type":"code","outputId":"f32af697-0e25-40f4-cb57-fe1e31ef17df","executionInfo":{"status":"ok","timestamp":1585836125696,"user_tz":240,"elapsed":340,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["print ('\\n Best manually tuned parameters:', best_xgb_params)\n","# Best manually tuned parameters: {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, \n","# 'seed': 1234, 'objective': 'reg:squarederror', 'alpha': 10, 'max_leaves': 3, \n","# 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Best manually tuned parameters: {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q19dDKb5LY86","colab_type":"text"},"source":["## Automated tuning\n","\n","We will be using a package BayesianOptimization for automated tuning. Results from manual tuning can be used to further narrow the space that needs to be searched from for better performance."]},{"cell_type":"code","metadata":{"id":"I9GkGvVXLXxO","colab_type":"code","outputId":"3489f9b7-1fa0-493e-9cdc-a6757a88bac2","executionInfo":{"status":"ok","timestamp":1585924156097,"user_tz":240,"elapsed":3960,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["!pip install bayesian-optimization"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting bayesian-optimization\n","  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.2)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n","Installing collected packages: bayesian-optimization\n","Successfully installed bayesian-optimization-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RwyMelrVLX2F","colab_type":"code","colab":{}},"source":["from bayes_opt import BayesianOptimization"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CcNwHGufbICf","colab_type":"text"},"source":["lgb vs xgb:\n","bagging_freq = Not have this feature \\\\\n","num_leaves = max_leaves \\\\\n","max_depth = max_depth \\\\\n","min_gain_to_split = gamma \\\\\n","feature_fraction = colsample_bytree \\\\\n","bagging_fraction = subsample \\\\\n","min_sum_hessian_in_leaf = min_child_weight \\\\\n","lambda_l2 = lambda \\\\\n","lambda_l1 = alpha \\\\"]},{"cell_type":"code","metadata":{"id":"rQjDuRQJLX7m","colab_type":"code","colab":{}},"source":["def xgb_evaluate(\n","    max_leaves,\n","    max_depth,\n","    min_child_weight,\n","    gamma,\n","    colsample_bytree,\n","    subsample,\n","    lambda_1,\n","    alpha\n","):\n","    params = dict()\n","    params['objective'] = 'reg:squarederror'\n","    params['learning_rate'] = 0.05\n","    params['seed'] = 1234\n","    params['max_leaves'] = int(max_leaves)\n","    params['max_depth'] = int(max_depth)\n","    params['min_child_weight'] = int(min_child_weight)\n","    params['gamma'] = gamma\n","    params['colsample_bytree'] = colsample_bytree\n","    params['subsample'] = subsample\n","    params['lambda'] = lambda_1\n","    params['alpha'] = alpha\n","    params[\"metric\"] = 'rmse'\n","\n","    xgb_cv = xgb.cv(params,\n","                xgb.DMatrix(train_x,\n","                            label=train_y\n","                            ),\n","                num_boost_round=100000,\n","                nfold=kfolds,\n","                folds=list(skf.split(train_y)),\n","                stratified=False,\n","                early_stopping_rounds=50,\n","                verbose_eval=500)\n","\n","    best_xgb_score = min(xgb_cv['test-rmse-mean'])\n","    best_xgb_iteration = len(xgb_cv['test-rmse-mean'])\n","    print(', best_score: %f, best_iteration: %d' %\n","          (best_xgb_score, best_xgb_iteration))\n","\n","    return -best_xgb_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"If0Hq4l922Qy","colab_type":"code","colab":{}},"source":["from bayes_opt.logger import JSONLogger\n","from bayes_opt.event import Events\n","\n","xgb_BO = BayesianOptimization(xgb_evaluate,\n","                              {\n","                                  'max_leaves': (7, 31),\n","                                  'max_depth': (7, 31),\n","                                  'min_child_weight': (0, 2),\n","                                  'gamma': (0, 5),\n","                                  'colsample_bytree': (0.3, 0.6),\n","                                  'subsample': (0.9, 1),\n","                                  'lambda_1': (0, 1),\n","                                  'alpha': (0, 1)\n","                              }\n","                              )\n","\n","logger = JSONLogger(path=\"/content/drive/My Drive/Kaggle_Allstate/data/logs.json\")\n","xgb_BO.subscribe(Events.OPTIMIZATION_STEP, logger)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m51prtU7LYGa","colab_type":"code","outputId":"c04fb857-4f7c-44ba-e2e7-6a4db7b646f6","executionInfo":{"status":"ok","timestamp":1585706298516,"user_tz":240,"elapsed":26453347,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["xgb_BO.maximize(init_points=5, n_iter=40) \n","# in the competition, we should use more than 25, below we use 6 points as example. \n","# xgb_BO.maximize(init_points=3, n_iter=3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0]\ttrain-rmse:6.97192+0.000373142\ttest-rmse:6.97193+0.00168466\n","[500]\ttrain-rmse:0.459881+0.000479221\ttest-rmse:0.478169+0.00199449\n","[1000]\ttrain-rmse:0.456016+0.000483969\ttest-rmse:0.477194+0.00201929\n","[1500]\ttrain-rmse:0.453914+0.000547095\ttest-rmse:0.476853+0.00204023\n","[2000]\ttrain-rmse:0.452427+0.000574524\ttest-rmse:0.476655+0.00203132\n","[2500]\ttrain-rmse:0.45127+0.000549957\ttest-rmse:0.476498+0.00201735\n","[3000]\ttrain-rmse:0.450265+0.000544427\ttest-rmse:0.476419+0.00203634\n","[3500]\ttrain-rmse:0.449402+0.000590384\ttest-rmse:0.476354+0.00203511\n",", best_score: 0.476316, best_iteration: 3874\n","[0]\ttrain-rmse:6.9717+0.000378212\ttest-rmse:6.97172+0.00169827\n","[500]\ttrain-rmse:0.395547+0.000627834\ttest-rmse:0.476584+0.00182212\n",", best_score: 0.476472, best_iteration: 784\n","[0]\ttrain-rmse:6.97214+0.000387931\ttest-rmse:6.97216+0.00161003\n","[500]\ttrain-rmse:0.381255+0.00066667\ttest-rmse:0.476276+0.00221044\n",", best_score: 0.476253, best_iteration: 548\n","[0]\ttrain-rmse:6.97177+0.000375456\ttest-rmse:6.97178+0.00169298\n","[500]\ttrain-rmse:0.42798+0.00050206\ttest-rmse:0.475285+0.00206089\n",", best_score: 0.475094, best_iteration: 913\n","[0]\ttrain-rmse:6.97215+0.000382239\ttest-rmse:6.97215+0.00162113\n","[500]\ttrain-rmse:0.43491+0.000566031\ttest-rmse:0.47549+0.00200204\n","[1000]\ttrain-rmse:0.430055+0.000883234\ttest-rmse:0.475191+0.0020053\n",", best_score: 0.475126, best_iteration: 1358\n","[0]\ttrain-rmse:6.97197+0.000394418\ttest-rmse:6.97196+0.00165794\n","[500]\ttrain-rmse:0.44282+0.000548763\ttest-rmse:0.477661+0.00214818\n","[1000]\ttrain-rmse:0.422151+0.000773903\ttest-rmse:0.476572+0.00221577\n",", best_score: 0.476480, best_iteration: 1103\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"phwEtk5U4Kvy","colab_type":"code","outputId":"7d94e97c-9b51-470d-cd4f-162daaaccd40","executionInfo":{"status":"ok","timestamp":1585713302701,"user_tz":240,"elapsed":434,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["xgb_BO.res"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'params': {'alpha': 0.05086376980654295,\n","   'colsample_bytree': 0.5033744688160208,\n","   'gamma': 2.6181622157861733,\n","   'lambda_1': 0.7397577084815677,\n","   'max_depth': 8.980030164189422,\n","   'max_leaves': 7.919551599788012,\n","   'min_child_weight': 0.14315591674782358,\n","   'subsample': 0.9051490453280847},\n","  'target': -0.47631560000000006},\n"," {'params': {'alpha': 0.09079001272675025,\n","   'colsample_bytree': 0.5866722945625281,\n","   'gamma': 1.6369095054960214,\n","   'lambda_1': 0.23024360375487152,\n","   'max_depth': 16.75553362632672,\n","   'max_leaves': 9.670825007221119,\n","   'min_child_weight': 1.3504049943390304,\n","   'subsample': 0.9799986550908285},\n","  'target': -0.4764724},\n"," {'params': {'alpha': 0.13689947520785584,\n","   'colsample_bytree': 0.355130661246054,\n","   'gamma': 1.453223371438881,\n","   'lambda_1': 0.7994357770097028,\n","   'max_depth': 21.77486770833211,\n","   'max_leaves': 18.567271497068546,\n","   'min_child_weight': 0.403000984901696,\n","   'subsample': 0.9982695479454914},\n","  'target': -0.47625340000000005},\n"," {'params': {'alpha': 0.8160280457593297,\n","   'colsample_bytree': 0.550221504424711,\n","   'gamma': 2.589283905724397,\n","   'lambda_1': 0.2961662273373261,\n","   'max_depth': 30.972090003962727,\n","   'max_leaves': 30.83688868596261,\n","   'min_child_weight': 1.7615439727423627,\n","   'subsample': 0.9716080823311943},\n","  'target': -0.475094},\n"," {'params': {'alpha': 0.1937658481758726,\n","   'colsample_bytree': 0.33823609157859263,\n","   'gamma': 2.9321231808765176,\n","   'lambda_1': 0.7755779092543663,\n","   'max_depth': 30.95384851936535,\n","   'max_leaves': 30.903632889226966,\n","   'min_child_weight': 0.5844614799033883,\n","   'subsample': 0.9979869113399464},\n","  'target': -0.4751258},\n"," {'params': {'alpha': 0.4363464635219775,\n","   'colsample_bytree': 0.42800023383579944,\n","   'gamma': 0.21248280400864628,\n","   'lambda_1': 0.8925367654668397,\n","   'max_depth': 7.317753023727065,\n","   'max_leaves': 30.768914023923216,\n","   'min_child_weight': 1.9357052269379063,\n","   'subsample': 0.9371010932361232},\n","  'target': -0.47647959999999995}]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"guiQN9tgkvw2","colab_type":"code","outputId":"7a27f019-7804-4bb7-87b1-c682913e0747","executionInfo":{"status":"ok","timestamp":1585714465229,"user_tz":240,"elapsed":358,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["xgb_BO_scores = pd.DataFrame()\n","for dic in xgb_BO.res:\n","  param = dic['params']\n","  param = pd.DataFrame([param])\n","  xgb_BO_scores = pd.concat([xgb_BO_scores, param], ignore_index=True)\n","\n","xgb_BO_scores"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alpha</th>\n","      <th>colsample_bytree</th>\n","      <th>gamma</th>\n","      <th>lambda_1</th>\n","      <th>max_depth</th>\n","      <th>max_leaves</th>\n","      <th>min_child_weight</th>\n","      <th>subsample</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.050864</td>\n","      <td>0.503374</td>\n","      <td>2.618162</td>\n","      <td>0.739758</td>\n","      <td>8.980030</td>\n","      <td>7.919552</td>\n","      <td>0.143156</td>\n","      <td>0.905149</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.090790</td>\n","      <td>0.586672</td>\n","      <td>1.636910</td>\n","      <td>0.230244</td>\n","      <td>16.755534</td>\n","      <td>9.670825</td>\n","      <td>1.350405</td>\n","      <td>0.979999</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.136899</td>\n","      <td>0.355131</td>\n","      <td>1.453223</td>\n","      <td>0.799436</td>\n","      <td>21.774868</td>\n","      <td>18.567271</td>\n","      <td>0.403001</td>\n","      <td>0.998270</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.816028</td>\n","      <td>0.550222</td>\n","      <td>2.589284</td>\n","      <td>0.296166</td>\n","      <td>30.972090</td>\n","      <td>30.836889</td>\n","      <td>1.761544</td>\n","      <td>0.971608</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.193766</td>\n","      <td>0.338236</td>\n","      <td>2.932123</td>\n","      <td>0.775578</td>\n","      <td>30.953849</td>\n","      <td>30.903633</td>\n","      <td>0.584461</td>\n","      <td>0.997987</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.436346</td>\n","      <td>0.428000</td>\n","      <td>0.212483</td>\n","      <td>0.892537</td>\n","      <td>7.317753</td>\n","      <td>30.768914</td>\n","      <td>1.935705</td>\n","      <td>0.937101</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      alpha  colsample_bytree  ...  min_child_weight  subsample\n","0  0.050864          0.503374  ...          0.143156   0.905149\n","1  0.090790          0.586672  ...          1.350405   0.979999\n","2  0.136899          0.355131  ...          0.403001   0.998270\n","3  0.816028          0.550222  ...          1.761544   0.971608\n","4  0.193766          0.338236  ...          0.584461   0.997987\n","5  0.436346          0.428000  ...          1.935705   0.937101\n","\n","[6 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"KBHFRn1E8T8R","colab_type":"code","outputId":"89eb43fc-5520-4d67-f4eb-cd9bf7ea6881","executionInfo":{"status":"ok","timestamp":1585714467253,"user_tz":240,"elapsed":376,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["xgb_BO_scores['score'] = pd.DataFrame(xgb_BO.res)['target']\n","xgb_BO_scores.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alpha</th>\n","      <th>colsample_bytree</th>\n","      <th>gamma</th>\n","      <th>lambda_1</th>\n","      <th>max_depth</th>\n","      <th>max_leaves</th>\n","      <th>min_child_weight</th>\n","      <th>subsample</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.050864</td>\n","      <td>0.503374</td>\n","      <td>2.618162</td>\n","      <td>0.739758</td>\n","      <td>8.980030</td>\n","      <td>7.919552</td>\n","      <td>0.143156</td>\n","      <td>0.905149</td>\n","      <td>-0.476316</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.090790</td>\n","      <td>0.586672</td>\n","      <td>1.636910</td>\n","      <td>0.230244</td>\n","      <td>16.755534</td>\n","      <td>9.670825</td>\n","      <td>1.350405</td>\n","      <td>0.979999</td>\n","      <td>-0.476472</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.136899</td>\n","      <td>0.355131</td>\n","      <td>1.453223</td>\n","      <td>0.799436</td>\n","      <td>21.774868</td>\n","      <td>18.567271</td>\n","      <td>0.403001</td>\n","      <td>0.998270</td>\n","      <td>-0.476253</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.816028</td>\n","      <td>0.550222</td>\n","      <td>2.589284</td>\n","      <td>0.296166</td>\n","      <td>30.972090</td>\n","      <td>30.836889</td>\n","      <td>1.761544</td>\n","      <td>0.971608</td>\n","      <td>-0.475094</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.193766</td>\n","      <td>0.338236</td>\n","      <td>2.932123</td>\n","      <td>0.775578</td>\n","      <td>30.953849</td>\n","      <td>30.903633</td>\n","      <td>0.584461</td>\n","      <td>0.997987</td>\n","      <td>-0.475126</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      alpha  colsample_bytree     gamma  ...  min_child_weight  subsample     score\n","0  0.050864          0.503374  2.618162  ...          0.143156   0.905149 -0.476316\n","1  0.090790          0.586672  1.636910  ...          1.350405   0.979999 -0.476472\n","2  0.136899          0.355131  1.453223  ...          0.403001   0.998270 -0.476253\n","3  0.816028          0.550222  2.589284  ...          1.761544   0.971608 -0.475094\n","4  0.193766          0.338236  2.932123  ...          0.584461   0.997987 -0.475126\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"4zzqeEd-7GbO","colab_type":"code","outputId":"a254d07c-b529-45b3-fda1-a24cc6ee23b1","executionInfo":{"status":"ok","timestamp":1585714470975,"user_tz":240,"elapsed":411,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["xgb_BO_scores = xgb_BO_scores.sort_values(by='score',ascending=False)\n","xgb_BO_scores.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alpha</th>\n","      <th>colsample_bytree</th>\n","      <th>gamma</th>\n","      <th>lambda_1</th>\n","      <th>max_depth</th>\n","      <th>max_leaves</th>\n","      <th>min_child_weight</th>\n","      <th>subsample</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0.816028</td>\n","      <td>0.550222</td>\n","      <td>2.589284</td>\n","      <td>0.296166</td>\n","      <td>30.972090</td>\n","      <td>30.836889</td>\n","      <td>1.761544</td>\n","      <td>0.971608</td>\n","      <td>-0.475094</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.193766</td>\n","      <td>0.338236</td>\n","      <td>2.932123</td>\n","      <td>0.775578</td>\n","      <td>30.953849</td>\n","      <td>30.903633</td>\n","      <td>0.584461</td>\n","      <td>0.997987</td>\n","      <td>-0.475126</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.136899</td>\n","      <td>0.355131</td>\n","      <td>1.453223</td>\n","      <td>0.799436</td>\n","      <td>21.774868</td>\n","      <td>18.567271</td>\n","      <td>0.403001</td>\n","      <td>0.998270</td>\n","      <td>-0.476253</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.050864</td>\n","      <td>0.503374</td>\n","      <td>2.618162</td>\n","      <td>0.739758</td>\n","      <td>8.980030</td>\n","      <td>7.919552</td>\n","      <td>0.143156</td>\n","      <td>0.905149</td>\n","      <td>-0.476316</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.090790</td>\n","      <td>0.586672</td>\n","      <td>1.636910</td>\n","      <td>0.230244</td>\n","      <td>16.755534</td>\n","      <td>9.670825</td>\n","      <td>1.350405</td>\n","      <td>0.979999</td>\n","      <td>-0.476472</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      alpha  colsample_bytree     gamma  ...  min_child_weight  subsample     score\n","3  0.816028          0.550222  2.589284  ...          1.761544   0.971608 -0.475094\n","4  0.193766          0.338236  2.932123  ...          0.584461   0.997987 -0.475126\n","2  0.136899          0.355131  1.453223  ...          0.403001   0.998270 -0.476253\n","0  0.050864          0.503374  2.618162  ...          0.143156   0.905149 -0.476316\n","1  0.090790          0.586672  1.636910  ...          1.350405   0.979999 -0.476472\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"ULCpUi5m7Kqd","colab_type":"code","colab":{}},"source":["xgb_BO_scores.to_csv(\"/content/drive/My Drive/Kaggle_Allstate/data/tuned_xgb_parameters.csv\", index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nB_QaDNGjUA","colab_type":"code","outputId":"982b09c0-0b72-4360-b78f-2f3b33db4d81","executionInfo":{"status":"ok","timestamp":1585836133356,"user_tz":240,"elapsed":455,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["xgb_BO_scores = pd.read_csv(\"/content/drive/My Drive/Kaggle_Allstate/data/tuned_xgb_parameters.csv\")\n","xgb_BO_scores.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alpha</th>\n","      <th>colsample_bytree</th>\n","      <th>gamma</th>\n","      <th>lambda_1</th>\n","      <th>max_depth</th>\n","      <th>max_leaves</th>\n","      <th>min_child_weight</th>\n","      <th>subsample</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.816028</td>\n","      <td>0.550222</td>\n","      <td>2.589284</td>\n","      <td>0.296166</td>\n","      <td>30.972090</td>\n","      <td>30.836889</td>\n","      <td>1.761544</td>\n","      <td>0.971608</td>\n","      <td>-0.475094</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.193766</td>\n","      <td>0.338236</td>\n","      <td>2.932123</td>\n","      <td>0.775578</td>\n","      <td>30.953849</td>\n","      <td>30.903633</td>\n","      <td>0.584461</td>\n","      <td>0.997987</td>\n","      <td>-0.475126</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.136899</td>\n","      <td>0.355131</td>\n","      <td>1.453223</td>\n","      <td>0.799436</td>\n","      <td>21.774868</td>\n","      <td>18.567271</td>\n","      <td>0.403001</td>\n","      <td>0.998270</td>\n","      <td>-0.476253</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.050864</td>\n","      <td>0.503374</td>\n","      <td>2.618162</td>\n","      <td>0.739758</td>\n","      <td>8.980030</td>\n","      <td>7.919552</td>\n","      <td>0.143156</td>\n","      <td>0.905149</td>\n","      <td>-0.476316</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.090790</td>\n","      <td>0.586672</td>\n","      <td>1.636910</td>\n","      <td>0.230244</td>\n","      <td>16.755534</td>\n","      <td>9.670825</td>\n","      <td>1.350405</td>\n","      <td>0.979999</td>\n","      <td>-0.476472</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      alpha  colsample_bytree     gamma  ...  min_child_weight  subsample     score\n","0  0.816028          0.550222  2.589284  ...          1.761544   0.971608 -0.475094\n","1  0.193766          0.338236  2.932123  ...          0.584461   0.997987 -0.475126\n","2  0.136899          0.355131  1.453223  ...          0.403001   0.998270 -0.476253\n","3  0.050864          0.503374  2.618162  ...          0.143156   0.905149 -0.476316\n","4  0.090790          0.586672  1.636910  ...          1.350405   0.979999 -0.476472\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"LZobiYtQ88gQ","colab_type":"text"},"source":["### Retrain the model with smaller learning rate \n","\n","lgb vs xgb:\n","bagging_freq = Not have this feature \\\\\n","num_leaves = max_leaves \\\\\n","max_depth = max_depth \\\\\n","min_gain_to_split = gamma \\\\\n","feature_fraction = colsample_bytree \\\\\n","bagging_fraction = subsample \\\\\n","min_sum_hessian_in_leaf = min_child_weight \\\\\n","lambda_l2 = lambda \\\\\n","lambda_l1 = alpha \\\\"]},{"cell_type":"code","metadata":{"id":"8tvNZsVr9NFQ","colab_type":"code","outputId":"2b257d78-5e71-4973-a1f6-b9e428f0fb0b","colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["params = xgb_BO_scores.iloc[0].to_dict()\n","best_auto_xgb_params = dict()\n","best_auto_xgb_params['objective'] = 'reg:squarederror'\n","best_auto_xgb_params[\"metric\"] = 'rmse'\n","best_auto_xgb_params['learning_rate'] = 0.01 # Smaller learning rate\n","best_auto_xgb_params['max_leaves'] = int(params['max_leaves'])    \n","best_auto_xgb_params['max_depth'] = int(params['max_depth'])    \n","best_auto_xgb_params['min_child_weight'] = int(params['min_child_weight'])\n","best_auto_xgb_params['gamma'] = params['gamma']     \n","best_auto_xgb_params['colsample_bytree'] = params['colsample_bytree']\n","best_auto_xgb_params['subsample'] = params['subsample']\n","best_auto_xgb_params['lambda'] = params['lambda_1']\n","best_auto_xgb_params['alpha'] = params['alpha']\n","best_auto_xgb_params['seed'] = 1234\n","\n","\n","print (best_auto_xgb_params)\n","\n","xgb_cv = xgb.cv(best_auto_xgb_params,\n","            xgb.DMatrix(train_x,\n","                        label=train_y\n","                        ),\n","            num_boost_round=100000,\n","            nfold=kfolds,\n","            folds=list(skf.split(train_y)),\n","            stratified=False,\n","            early_stopping_rounds=50,\n","            verbose_eval=500)\n","\n","best_xgb_score = min(xgb_cv['test-rmse-mean'])\n","best_xgb_iteration = len(xgb_cv['test-rmse-mean'])\n","print (', best_score: %f, best_iteration: %d' % (best_xgb_score, best_xgb_iteration))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'objective': 'reg:squarederror', 'metric': 'rmse', 'learning_rate': 0.01, 'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.550221504424711, 'subsample': 0.9716080823311943, 'lambda': 0.2961662273373261, 'alpha': 0.8160280457593297, 'seed': 1234}\n","[0]\ttrain-rmse:7.26347+0.000394666\ttest-rmse:7.26347+0.00161554\n","[500]\ttrain-rmse:0.454827+0.000438066\ttest-rmse:0.483081+0.00207937\n","[1000]\ttrain-rmse:0.437947+0.000528251\ttest-rmse:0.475721+0.0020776\n","[1500]\ttrain-rmse:0.433034+0.000425967\ttest-rmse:0.474796+0.00212813\n","[2000]\ttrain-rmse:0.429989+0.000359508\ttest-rmse:0.474426+0.00214303\n","[2500]\ttrain-rmse:0.427732+0.00031817\ttest-rmse:0.47424+0.00215785\n","[3000]\ttrain-rmse:0.425936+0.000326178\ttest-rmse:0.474114+0.00215574\n","[3500]\ttrain-rmse:0.424409+0.000281457\ttest-rmse:0.474053+0.00217526\n","[4000]\ttrain-rmse:0.423086+0.000291358\ttest-rmse:0.474008+0.0021805\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NWgtEqdu9NCr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SlHh3nk9M_q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lL95d8yN9M8V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FJ_S61dUUAds","colab_type":"text"},"source":["## XGBosst blending function \n","\n","1. KFold.split()返回的是(train_idx, test_idx)，在旧版本中KFold()返回的是(train_idx, test_idx)\n"]},{"cell_type":"code","metadata":{"id":"adXe7YglTMGL","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import StratifiedKFold, KFold \n","import copy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vvQTiKCqUbKB","colab_type":"code","colab":{}},"source":["def xgb_blend(xgb_params, train_x, train_y, test_x, kfolds, early_stopping_rounds=0, train_y_dummy=None):\n","    \"\"\"\n","    estimator: parameters \n","    \"\"\"\n","    print(f\"Blend {len(xgb_params)} estimators for {kfolds} folds\")\n","    skf = KFold(n_splits=kfolds, random_state=1234)\n","    skf_ids = list(skf.split(train_y))\n","\n","    train_blend_x = np.zeros((train_x.shape[0], len(xgb_params)))\n","    test_blend_x = np.zeros((test_x.shape[0], len(xgb_params)))\n","    blend_scores = np.zeros ((kfolds,len(xgb_params)))\n","    best_rounds = np.zeros ((kfolds,len(xgb_params)))\n","\n","    print(\"Start stacking\")\n","\n","    for j, est in enumerate(xgb_params):\n","        print(\"Stacking model\", j+1, est)\n","        test_blend_x_j = np.zeros((test_x.shape[0]))\n","        for i, (train_ids, val_ids) in enumerate(skf_ids):\n","            start = time.time()\n","            print (f\"Model {j+1} fold {i+1}\")\n","            train_x_fold = train_x[train_ids]\n","            train_y_fold = train_y[train_ids]\n","            val_x_fold = train_x[val_ids]\n","            val_y_fold = train_y[val_ids]\n","            print(i, est)\n","\n","            if early_stopping_rounds == 0: \n","                #without early stoping\n","                num_boost_round = copy.deepcopy(params['num_boost_round'])\n","                model = xgb.train(params, \n","                                  xgb.DMatrix(train_x_fold, \n","                                              train_y_fold\n","                                              ),\n","                                  num_boost_round=num_boost_round,\n","                                  verbose_eval=500\n","                                  )\n","                val_y_predict_fold = model.predict(xgb.DMatrix(val_x_fold))\n","                socre = log_mae(val_y_fold, val_y_predict_fold, 200)\n","                print(f\"Score for Model {j+1} fold {i+1}: {score}\")\n","                blend_scores[i, j] = score\n","                train_blend_x[val_ids, j] = val_y_predict_fold\n","                test_blend_x_j = test_blend_x_j + model.predict(xgb.DMatrix(test_x))\n","                print(f\"Model {j+1} fold {i+1} finished in {time.time()-start} seconds.\")\n","            else:\n","                valid_data = xgb.DMatrix(val_x_fold, val_y_fold)\n","                model = xgb.train(params,\n","                                  xgb.DMatrix(train_x_fold,\n","                                              train_y_fold\n","                                              ),\n","                                  evals=[(valid_data, 'valid')], \n","                                  num_boost_round=10000000,\n","                                  early_stopping_rounds=early_stopping_rounds, \n","                                  verbose_eval=500)\n","                best_iteration = model.best_iteration\n","                best_ntree_limit = model.best_ntree_limit\n","                best_rounds[i, j] = best_iteration\n","                print(f\"best iteration: {best_iteration}\")\n","                print(f\"best score: {model.best_score}\")\n","                val_y_predict_fold = model.predict(xgb.DMatrix(val_x_fold), ntree_limit=best_ntree_limit)\n","                score = log_mae(val_y_fold, val_y_predict_fold, 200)\n","                print(f\"Score for Model {j+1} fold {i+1}: {score}\")\n","                blend_scores[i, j] = score \n","                train_blend_x[val_ids, j] = val_y_predict_fold\n","                test_blend_x_j = test_blend_x_j + model.predict(xgb.DMatrix(test_x), ntree_limit=best_ntree_limit)\n","                print(f\"Model {j+1} fold {i+1} finished in {time.time()-start}\")\n","\n","        test_blend_x[:, j]= test_blend_x_j / kfolds\n","        print(f\"Score for model {j+1} is {np.mean(blend_scores[:, j])}\")\n","    print(f\"Socre for blended models is {np.mean(blend_scores)}\")\n","    return train_blend_x, test_blend_x, blend_scores"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG42_DpSVh0y","colab_type":"text"},"source":["### Select top 4 XGBoost models \n","\n","lgb vs xgb:\n","bagging_freq = Not have this feature \\\\\n","num_leaves = max_leaves \\\\\n","max_depth = max_depth \\\\\n","min_gain_to_split = gamma \\\\\n","feature_fraction = colsample_bytree \\\\\n","bagging_fraction = subsample \\\\\n","min_sum_hessian_in_leaf = min_child_weight \\\\\n","lambda_l2 = lambda \\\\\n","lambda_l1 = alpha \\\\"]},{"cell_type":"code","metadata":{"id":"ysCLWftaaub0","colab_type":"code","outputId":"0218a7e0-9650-4804-d34d-bb50c4f36c8d","executionInfo":{"status":"ok","timestamp":1585836150320,"user_tz":240,"elapsed":562,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["xgb_params = []\n","## Top 5 auto-tuned parameters\n","for i in range(4):\n","    params=dict()\n","    params['max_leaves'] = int(xgb_BO_scores['max_leaves'][i])\n","    params['max_depth'] = int(xgb_BO_scores['max_depth'][i])\n","    params['min_child_weight'] = int(xgb_BO_scores['min_child_weight'][i])\n","    params['gamma'] = xgb_BO_scores['gamma'][i]\n","    params['colsample_bytree'] = xgb_BO_scores['colsample_bytree'][i]\n","    params['subsample'] = xgb_BO_scores['subsample'][i]\n","    params['lambda_1'] = xgb_BO_scores['lambda_1'][i]\n","    params['alpha'] = int(xgb_BO_scores['alpha'][i])\n","    params['objective'] = 'reg:squarederror'\n","    params['learning_rate'] = 0.05\n","    params['num_boost_round']= best_xgb_iteration # use the result best_xgb_iteration from the cell Retrain the model with smaller learning rate, here use a example value \n","    params['seed'] = 1234\n","    params[\"metric\"] = 'rmse'\n","    xgb_params.append(params)\n","\n","## Best manual-tuned parameters\n","xgb_params.append(best_xgb_params)    \n","print(xgb_params)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[{'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.5502215044247111, 'subsample': 0.9716080823311944, 'lambda_1': 0.2961662273373261, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}, {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 0, 'gamma': 2.9321231808765176, 'colsample_bytree': 0.33823609157859263, 'subsample': 0.9979869113399464, 'lambda_1': 0.7755779092543663, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}, {'max_leaves': 18, 'max_depth': 21, 'min_child_weight': 0, 'gamma': 1.453223371438881, 'colsample_bytree': 0.35513066124605397, 'subsample': 0.9982695479454914, 'lambda_1': 0.7994357770097028, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}, {'max_leaves': 7, 'max_depth': 8, 'min_child_weight': 0, 'gamma': 2.6181622157861733, 'colsample_bytree': 0.5033744688160208, 'subsample': 0.9051490453280848, 'lambda_1': 0.7397577084815677, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}, {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EOtik44sbG4E","colab_type":"code","outputId":"78858b70-da46-4fba-b40e-b9cf190c8aa4","executionInfo":{"status":"ok","timestamp":1585836154890,"user_tz":240,"elapsed":352,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(train_x)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["scipy.sparse.csr.csr_matrix"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"Sg9c8Jz2DR4Y","colab_type":"code","outputId":"a3ca62f5-4f17-408b-f719-9fb742000bdc","executionInfo":{"status":"ok","timestamp":1585836157071,"user_tz":240,"elapsed":665,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_x.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(125546, 1190)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"1bsJbYpBbG9d","colab_type":"code","outputId":"79a148d5-6d01-4e30-c2c8-d3a5aca11480","executionInfo":{"status":"ok","timestamp":1585877000531,"user_tz":240,"elapsed":40840969,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_blend_x_xgb_ohe, test_blend_x_xgb_ohe, blend_scores_xgb_ohe = xgb_blend(xgb_params, train_x, train_y, test_x, 4, 1000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Blend 5 estimators for 4 folds\n","Start stacking\n","Stacking model 1 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.5502215044247111, 'subsample': 0.9716080823311944, 'lambda_1': 0.2961662273373261, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","Model 1 fold 1\n","0 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.5502215044247111, 'subsample': 0.9716080823311944, 'lambda_1': 0.2961662273373261, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["[0]\tvalid-rmse:6.96996\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477799\n","[1000]\tvalid-rmse:0.476925\n","[1500]\tvalid-rmse:0.476611\n","[2000]\tvalid-rmse:0.476452\n","[2500]\tvalid-rmse:0.476292\n","[3000]\tvalid-rmse:0.476198\n","[3500]\tvalid-rmse:0.476102\n","[4000]\tvalid-rmse:0.475978\n","[4500]\tvalid-rmse:0.475925\n","[5000]\tvalid-rmse:0.47588\n","[5500]\tvalid-rmse:0.475838\n","[6000]\tvalid-rmse:0.475838\n","[6500]\tvalid-rmse:0.47581\n","[7000]\tvalid-rmse:0.475792\n","[7500]\tvalid-rmse:0.475763\n","[8000]\tvalid-rmse:0.47571\n","[8500]\tvalid-rmse:0.475717\n","[9000]\tvalid-rmse:0.475734\n","Stopping. Best iteration:\n","[8056]\tvalid-rmse:0.475699\n","\n","best iteration: 8056\n","best score: 0.475699\n","Score for Model 1 fold 1: 1138.5577464832966\n","Model 1 fold 1 finished in 2556.266452550888\n","Model 1 fold 2\n","1 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.5502215044247111, 'subsample': 0.9716080823311944, 'lambda_1': 0.2961662273373261, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.9746\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477932\n","[1000]\tvalid-rmse:0.476913\n","[1500]\tvalid-rmse:0.476605\n","[2000]\tvalid-rmse:0.476434\n","[2500]\tvalid-rmse:0.476328\n","[3000]\tvalid-rmse:0.476246\n","[3500]\tvalid-rmse:0.476173\n","[4000]\tvalid-rmse:0.476098\n","[4500]\tvalid-rmse:0.476093\n","[5000]\tvalid-rmse:0.47607\n","Stopping. Best iteration:\n","[4087]\tvalid-rmse:0.476062\n","\n","best iteration: 4087\n","best score: 0.476062\n","Score for Model 1 fold 2: 1144.6437261623748\n","Model 1 fold 2 finished in 1443.365191936493\n","Model 1 fold 3\n","2 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.5502215044247111, 'subsample': 0.9716080823311944, 'lambda_1': 0.2961662273373261, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96984\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.479849\n","[1000]\tvalid-rmse:0.479137\n","[1500]\tvalid-rmse:0.47877\n","[2000]\tvalid-rmse:0.478608\n","[2500]\tvalid-rmse:0.478444\n","[3000]\tvalid-rmse:0.478383\n","[3500]\tvalid-rmse:0.478265\n","[4000]\tvalid-rmse:0.47824\n","[4500]\tvalid-rmse:0.478172\n","[5000]\tvalid-rmse:0.478144\n","[5500]\tvalid-rmse:0.478108\n","[6000]\tvalid-rmse:0.478066\n","[6500]\tvalid-rmse:0.478019\n","[7000]\tvalid-rmse:0.478064\n","Stopping. Best iteration:\n","[6394]\tvalid-rmse:0.478013\n","\n","best iteration: 6394\n","best score: 0.478013\n","Score for Model 1 fold 3: 1138.189053750785\n","Model 1 fold 3 finished in 2097.839597225189\n","Model 1 fold 4\n","3 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 1, 'gamma': 2.589283905724397, 'colsample_bytree': 0.5502215044247111, 'subsample': 0.9716080823311944, 'lambda_1': 0.2961662273373261, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.97338\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477662\n","[1000]\tvalid-rmse:0.476838\n","[1500]\tvalid-rmse:0.476466\n","[2000]\tvalid-rmse:0.476298\n","[2500]\tvalid-rmse:0.476219\n","[3000]\tvalid-rmse:0.476174\n","[3500]\tvalid-rmse:0.476111\n","[4000]\tvalid-rmse:0.476008\n","[4500]\tvalid-rmse:0.47598\n","[5000]\tvalid-rmse:0.475947\n","[5500]\tvalid-rmse:0.475913\n","[6000]\tvalid-rmse:0.475843\n","[6500]\tvalid-rmse:0.475846\n","[7000]\tvalid-rmse:0.475848\n","Stopping. Best iteration:\n","[6059]\tvalid-rmse:0.475836\n","\n","best iteration: 6059\n","best score: 0.475836\n","Score for Model 1 fold 4: 1137.908844903594\n","Model 1 fold 4 finished in 1985.9780204296112\n","Score for model 1 is 1139.8248428250126\n","Stacking model 2 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 0, 'gamma': 2.9321231808765176, 'colsample_bytree': 0.33823609157859263, 'subsample': 0.9979869113399464, 'lambda_1': 0.7755779092543663, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","Model 2 fold 1\n","0 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 0, 'gamma': 2.9321231808765176, 'colsample_bytree': 0.33823609157859263, 'subsample': 0.9979869113399464, 'lambda_1': 0.7755779092543663, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96996\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477799\n","[1000]\tvalid-rmse:0.476925\n","[1500]\tvalid-rmse:0.476611\n","[2000]\tvalid-rmse:0.476452\n","[2500]\tvalid-rmse:0.476292\n","[3000]\tvalid-rmse:0.476198\n","[3500]\tvalid-rmse:0.476102\n","[4000]\tvalid-rmse:0.475978\n","[4500]\tvalid-rmse:0.475925\n","[5000]\tvalid-rmse:0.47588\n","[5500]\tvalid-rmse:0.475838\n","[6000]\tvalid-rmse:0.475838\n","[6500]\tvalid-rmse:0.47581\n","[7000]\tvalid-rmse:0.475792\n","[7500]\tvalid-rmse:0.475763\n","[8000]\tvalid-rmse:0.47571\n","[8500]\tvalid-rmse:0.475717\n","[9000]\tvalid-rmse:0.475734\n","Stopping. Best iteration:\n","[8056]\tvalid-rmse:0.475699\n","\n","best iteration: 8056\n","best score: 0.475699\n","Score for Model 2 fold 1: 1138.5577464832966\n","Model 2 fold 1 finished in 2599.1458916664124\n","Model 2 fold 2\n","1 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 0, 'gamma': 2.9321231808765176, 'colsample_bytree': 0.33823609157859263, 'subsample': 0.9979869113399464, 'lambda_1': 0.7755779092543663, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.9746\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477932\n","[1000]\tvalid-rmse:0.476913\n","[1500]\tvalid-rmse:0.476605\n","[2000]\tvalid-rmse:0.476434\n","[2500]\tvalid-rmse:0.476328\n","[3000]\tvalid-rmse:0.476246\n","[3500]\tvalid-rmse:0.476173\n","[4000]\tvalid-rmse:0.476098\n","[4500]\tvalid-rmse:0.476093\n","[5000]\tvalid-rmse:0.47607\n","Stopping. Best iteration:\n","[4087]\tvalid-rmse:0.476062\n","\n","best iteration: 4087\n","best score: 0.476062\n","Score for Model 2 fold 2: 1144.6437261623748\n","Model 2 fold 2 finished in 1487.5080556869507\n","Model 2 fold 3\n","2 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 0, 'gamma': 2.9321231808765176, 'colsample_bytree': 0.33823609157859263, 'subsample': 0.9979869113399464, 'lambda_1': 0.7755779092543663, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96984\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.479849\n","[1000]\tvalid-rmse:0.479137\n","[1500]\tvalid-rmse:0.47877\n","[2000]\tvalid-rmse:0.478608\n","[2500]\tvalid-rmse:0.478444\n","[3000]\tvalid-rmse:0.478383\n","[3500]\tvalid-rmse:0.478265\n","[4000]\tvalid-rmse:0.47824\n","[4500]\tvalid-rmse:0.478172\n","[5000]\tvalid-rmse:0.478144\n","[5500]\tvalid-rmse:0.478108\n","[6000]\tvalid-rmse:0.478066\n","[6500]\tvalid-rmse:0.478019\n","[7000]\tvalid-rmse:0.478064\n","Stopping. Best iteration:\n","[6394]\tvalid-rmse:0.478013\n","\n","best iteration: 6394\n","best score: 0.478013\n","Score for Model 2 fold 3: 1138.189053750785\n","Model 2 fold 3 finished in 2142.011482000351\n","Model 2 fold 4\n","3 {'max_leaves': 30, 'max_depth': 30, 'min_child_weight': 0, 'gamma': 2.9321231808765176, 'colsample_bytree': 0.33823609157859263, 'subsample': 0.9979869113399464, 'lambda_1': 0.7755779092543663, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.97338\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477662\n","[1000]\tvalid-rmse:0.476838\n","[1500]\tvalid-rmse:0.476466\n","[2000]\tvalid-rmse:0.476298\n","[2500]\tvalid-rmse:0.476219\n","[3000]\tvalid-rmse:0.476174\n","[3500]\tvalid-rmse:0.476111\n","[4000]\tvalid-rmse:0.476008\n","[4500]\tvalid-rmse:0.47598\n","[5000]\tvalid-rmse:0.475947\n","[5500]\tvalid-rmse:0.475913\n","[6000]\tvalid-rmse:0.475843\n","[6500]\tvalid-rmse:0.475846\n","[7000]\tvalid-rmse:0.475848\n","Stopping. Best iteration:\n","[6059]\tvalid-rmse:0.475836\n","\n","best iteration: 6059\n","best score: 0.475836\n","Score for Model 2 fold 4: 1137.908844903594\n","Model 2 fold 4 finished in 2015.9319341182709\n","Score for model 2 is 1139.8248428250126\n","Stacking model 3 {'max_leaves': 18, 'max_depth': 21, 'min_child_weight': 0, 'gamma': 1.453223371438881, 'colsample_bytree': 0.35513066124605397, 'subsample': 0.9982695479454914, 'lambda_1': 0.7994357770097028, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","Model 3 fold 1\n","0 {'max_leaves': 18, 'max_depth': 21, 'min_child_weight': 0, 'gamma': 1.453223371438881, 'colsample_bytree': 0.35513066124605397, 'subsample': 0.9982695479454914, 'lambda_1': 0.7994357770097028, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96996\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477799\n","[1000]\tvalid-rmse:0.476925\n","[1500]\tvalid-rmse:0.476611\n","[2000]\tvalid-rmse:0.476452\n","[2500]\tvalid-rmse:0.476292\n","[3000]\tvalid-rmse:0.476198\n","[3500]\tvalid-rmse:0.476102\n","[4000]\tvalid-rmse:0.475978\n","[4500]\tvalid-rmse:0.475925\n","[5000]\tvalid-rmse:0.47588\n","[5500]\tvalid-rmse:0.475838\n","[6000]\tvalid-rmse:0.475838\n","[6500]\tvalid-rmse:0.47581\n","[7000]\tvalid-rmse:0.475792\n","[7500]\tvalid-rmse:0.475763\n","[8000]\tvalid-rmse:0.47571\n","[8500]\tvalid-rmse:0.475717\n","[9000]\tvalid-rmse:0.475734\n","Stopping. Best iteration:\n","[8056]\tvalid-rmse:0.475699\n","\n","best iteration: 8056\n","best score: 0.475699\n","Score for Model 3 fold 1: 1138.5577464832966\n","Model 3 fold 1 finished in 2569.4459371566772\n","Model 3 fold 2\n","1 {'max_leaves': 18, 'max_depth': 21, 'min_child_weight': 0, 'gamma': 1.453223371438881, 'colsample_bytree': 0.35513066124605397, 'subsample': 0.9982695479454914, 'lambda_1': 0.7994357770097028, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.9746\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477932\n","[1000]\tvalid-rmse:0.476913\n","[1500]\tvalid-rmse:0.476605\n","[2000]\tvalid-rmse:0.476434\n","[2500]\tvalid-rmse:0.476328\n","[3000]\tvalid-rmse:0.476246\n","[3500]\tvalid-rmse:0.476173\n","[4000]\tvalid-rmse:0.476098\n","[4500]\tvalid-rmse:0.476093\n","[5000]\tvalid-rmse:0.47607\n","Stopping. Best iteration:\n","[4087]\tvalid-rmse:0.476062\n","\n","best iteration: 4087\n","best score: 0.476062\n","Score for Model 3 fold 2: 1144.6437261623748\n","Model 3 fold 2 finished in 1465.9829683303833\n","Model 3 fold 3\n","2 {'max_leaves': 18, 'max_depth': 21, 'min_child_weight': 0, 'gamma': 1.453223371438881, 'colsample_bytree': 0.35513066124605397, 'subsample': 0.9982695479454914, 'lambda_1': 0.7994357770097028, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96984\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.479849\n","[1000]\tvalid-rmse:0.479137\n","[1500]\tvalid-rmse:0.47877\n","[2000]\tvalid-rmse:0.478608\n","[2500]\tvalid-rmse:0.478444\n","[3000]\tvalid-rmse:0.478383\n","[3500]\tvalid-rmse:0.478265\n","[4000]\tvalid-rmse:0.47824\n","[4500]\tvalid-rmse:0.478172\n","[5000]\tvalid-rmse:0.478144\n","[5500]\tvalid-rmse:0.478108\n","[6000]\tvalid-rmse:0.478066\n","[6500]\tvalid-rmse:0.478019\n","[7000]\tvalid-rmse:0.478064\n","Stopping. Best iteration:\n","[6394]\tvalid-rmse:0.478013\n","\n","best iteration: 6394\n","best score: 0.478013\n","Score for Model 3 fold 3: 1138.189053750785\n","Model 3 fold 3 finished in 2119.7966525554657\n","Model 3 fold 4\n","3 {'max_leaves': 18, 'max_depth': 21, 'min_child_weight': 0, 'gamma': 1.453223371438881, 'colsample_bytree': 0.35513066124605397, 'subsample': 0.9982695479454914, 'lambda_1': 0.7994357770097028, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.97338\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477662\n","[1000]\tvalid-rmse:0.476838\n","[1500]\tvalid-rmse:0.476466\n","[2000]\tvalid-rmse:0.476298\n","[2500]\tvalid-rmse:0.476219\n","[3000]\tvalid-rmse:0.476174\n","[3500]\tvalid-rmse:0.476111\n","[4000]\tvalid-rmse:0.476008\n","[4500]\tvalid-rmse:0.47598\n","[5000]\tvalid-rmse:0.475947\n","[5500]\tvalid-rmse:0.475913\n","[6000]\tvalid-rmse:0.475843\n","[6500]\tvalid-rmse:0.475846\n","[7000]\tvalid-rmse:0.475848\n","Stopping. Best iteration:\n","[6059]\tvalid-rmse:0.475836\n","\n","best iteration: 6059\n","best score: 0.475836\n","Score for Model 3 fold 4: 1137.908844903594\n","Model 3 fold 4 finished in 2004.908709526062\n","Score for model 3 is 1139.8248428250126\n","Stacking model 4 {'max_leaves': 7, 'max_depth': 8, 'min_child_weight': 0, 'gamma': 2.6181622157861733, 'colsample_bytree': 0.5033744688160208, 'subsample': 0.9051490453280848, 'lambda_1': 0.7397577084815677, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","Model 4 fold 1\n","0 {'max_leaves': 7, 'max_depth': 8, 'min_child_weight': 0, 'gamma': 2.6181622157861733, 'colsample_bytree': 0.5033744688160208, 'subsample': 0.9051490453280848, 'lambda_1': 0.7397577084815677, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96996\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477799\n","[1000]\tvalid-rmse:0.476925\n","[1500]\tvalid-rmse:0.476611\n","[2000]\tvalid-rmse:0.476452\n","[2500]\tvalid-rmse:0.476292\n","[3000]\tvalid-rmse:0.476198\n","[3500]\tvalid-rmse:0.476102\n","[4000]\tvalid-rmse:0.475978\n","[4500]\tvalid-rmse:0.475925\n","[5000]\tvalid-rmse:0.47588\n","[5500]\tvalid-rmse:0.475838\n","[6000]\tvalid-rmse:0.475838\n","[6500]\tvalid-rmse:0.47581\n","[7000]\tvalid-rmse:0.475792\n","[7500]\tvalid-rmse:0.475763\n","[8000]\tvalid-rmse:0.47571\n","[8500]\tvalid-rmse:0.475717\n","[9000]\tvalid-rmse:0.475734\n","Stopping. Best iteration:\n","[8056]\tvalid-rmse:0.475699\n","\n","best iteration: 8056\n","best score: 0.475699\n","Score for Model 4 fold 1: 1138.5577464832966\n","Model 4 fold 1 finished in 2589.2625319957733\n","Model 4 fold 2\n","1 {'max_leaves': 7, 'max_depth': 8, 'min_child_weight': 0, 'gamma': 2.6181622157861733, 'colsample_bytree': 0.5033744688160208, 'subsample': 0.9051490453280848, 'lambda_1': 0.7397577084815677, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.9746\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477932\n","[1000]\tvalid-rmse:0.476913\n","[1500]\tvalid-rmse:0.476605\n","[2000]\tvalid-rmse:0.476434\n","[2500]\tvalid-rmse:0.476328\n","[3000]\tvalid-rmse:0.476246\n","[3500]\tvalid-rmse:0.476173\n","[4000]\tvalid-rmse:0.476098\n","[4500]\tvalid-rmse:0.476093\n","[5000]\tvalid-rmse:0.47607\n","Stopping. Best iteration:\n","[4087]\tvalid-rmse:0.476062\n","\n","best iteration: 4087\n","best score: 0.476062\n","Score for Model 4 fold 2: 1144.6437261623748\n","Model 4 fold 2 finished in 1462.0135972499847\n","Model 4 fold 3\n","2 {'max_leaves': 7, 'max_depth': 8, 'min_child_weight': 0, 'gamma': 2.6181622157861733, 'colsample_bytree': 0.5033744688160208, 'subsample': 0.9051490453280848, 'lambda_1': 0.7397577084815677, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.96984\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.479849\n","[1000]\tvalid-rmse:0.479137\n","[1500]\tvalid-rmse:0.47877\n","[2000]\tvalid-rmse:0.478608\n","[2500]\tvalid-rmse:0.478444\n","[3000]\tvalid-rmse:0.478383\n","[3500]\tvalid-rmse:0.478265\n","[4000]\tvalid-rmse:0.47824\n","[4500]\tvalid-rmse:0.478172\n","[5000]\tvalid-rmse:0.478144\n","[5500]\tvalid-rmse:0.478108\n","[6000]\tvalid-rmse:0.478066\n","[6500]\tvalid-rmse:0.478019\n","[7000]\tvalid-rmse:0.478064\n","Stopping. Best iteration:\n","[6394]\tvalid-rmse:0.478013\n","\n","best iteration: 6394\n","best score: 0.478013\n","Score for Model 4 fold 3: 1138.189053750785\n","Model 4 fold 3 finished in 2103.8853883743286\n","Model 4 fold 4\n","3 {'max_leaves': 7, 'max_depth': 8, 'min_child_weight': 0, 'gamma': 2.6181622157861733, 'colsample_bytree': 0.5033744688160208, 'subsample': 0.9051490453280848, 'lambda_1': 0.7397577084815677, 'alpha': 0, 'objective': 'reg:squarederror', 'learning_rate': 0.05, 'num_boost_round': 2000, 'seed': 1234, 'metric': 'rmse'}\n","[0]\tvalid-rmse:6.97338\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477662\n","[1000]\tvalid-rmse:0.476838\n","[1500]\tvalid-rmse:0.476466\n","[2000]\tvalid-rmse:0.476298\n","[2500]\tvalid-rmse:0.476219\n","[3000]\tvalid-rmse:0.476174\n","[3500]\tvalid-rmse:0.476111\n","[4000]\tvalid-rmse:0.476008\n","[4500]\tvalid-rmse:0.47598\n","[5000]\tvalid-rmse:0.475947\n","[5500]\tvalid-rmse:0.475913\n","[6000]\tvalid-rmse:0.475843\n","[6500]\tvalid-rmse:0.475846\n","[7000]\tvalid-rmse:0.475848\n","Stopping. Best iteration:\n","[6059]\tvalid-rmse:0.475836\n","\n","best iteration: 6059\n","best score: 0.475836\n","Score for Model 4 fold 4: 1137.908844903594\n","Model 4 fold 4 finished in 2000.0225884914398\n","Score for model 4 is 1139.8248428250126\n","Stacking model 5 {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}\n","Model 5 fold 1\n","0 {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}\n","[0]\tvalid-rmse:6.96996\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477799\n","[1000]\tvalid-rmse:0.476925\n","[1500]\tvalid-rmse:0.476611\n","[2000]\tvalid-rmse:0.476452\n","[2500]\tvalid-rmse:0.476292\n","[3000]\tvalid-rmse:0.476198\n","[3500]\tvalid-rmse:0.476102\n","[4000]\tvalid-rmse:0.475978\n","[4500]\tvalid-rmse:0.475925\n","[5000]\tvalid-rmse:0.47588\n","[5500]\tvalid-rmse:0.475838\n","[6000]\tvalid-rmse:0.475838\n","[6500]\tvalid-rmse:0.47581\n","[7000]\tvalid-rmse:0.475792\n","[7500]\tvalid-rmse:0.475763\n","[8000]\tvalid-rmse:0.47571\n","[8500]\tvalid-rmse:0.475717\n","[9000]\tvalid-rmse:0.475734\n","Stopping. Best iteration:\n","[8056]\tvalid-rmse:0.475699\n","\n","best iteration: 8056\n","best score: 0.475699\n","Score for Model 5 fold 1: 1138.5577464832966\n","Model 5 fold 1 finished in 2578.3058202266693\n","Model 5 fold 2\n","1 {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}\n","[0]\tvalid-rmse:6.9746\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477932\n","[1000]\tvalid-rmse:0.476913\n","[1500]\tvalid-rmse:0.476605\n","[2000]\tvalid-rmse:0.476434\n","[2500]\tvalid-rmse:0.476328\n","[3000]\tvalid-rmse:0.476246\n","[3500]\tvalid-rmse:0.476173\n","[4000]\tvalid-rmse:0.476098\n","[4500]\tvalid-rmse:0.476093\n","[5000]\tvalid-rmse:0.47607\n","Stopping. Best iteration:\n","[4087]\tvalid-rmse:0.476062\n","\n","best iteration: 4087\n","best score: 0.476062\n","Score for Model 5 fold 2: 1144.6437261623748\n","Model 5 fold 2 finished in 1476.345975637436\n","Model 5 fold 3\n","2 {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}\n","[0]\tvalid-rmse:6.96984\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.479849\n","[1000]\tvalid-rmse:0.479137\n","[1500]\tvalid-rmse:0.47877\n","[2000]\tvalid-rmse:0.478608\n","[2500]\tvalid-rmse:0.478444\n","[3000]\tvalid-rmse:0.478383\n","[3500]\tvalid-rmse:0.478265\n","[4000]\tvalid-rmse:0.47824\n","[4500]\tvalid-rmse:0.478172\n","[5000]\tvalid-rmse:0.478144\n","[5500]\tvalid-rmse:0.478108\n","[6000]\tvalid-rmse:0.478066\n","[6500]\tvalid-rmse:0.478019\n","[7000]\tvalid-rmse:0.478064\n","Stopping. Best iteration:\n","[6394]\tvalid-rmse:0.478013\n","\n","best iteration: 6394\n","best score: 0.478013\n","Score for Model 5 fold 3: 1138.189053750785\n","Model 5 fold 3 finished in 2122.1174545288086\n","Model 5 fold 4\n","3 {'learning_rate': 0.05, 'metrics': 'rmse', 'subsample': 1, 'seed': 1234, 'objective': 'reg:squarederror', 'max_leaves': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.1, 'min_child_weight': 100, 'lambda': 100, 'alpha': 10}\n","[0]\tvalid-rmse:6.97338\n","Will train until valid-rmse hasn't improved in 1000 rounds.\n","[500]\tvalid-rmse:0.477662\n","[1000]\tvalid-rmse:0.476838\n","[1500]\tvalid-rmse:0.476466\n","[2000]\tvalid-rmse:0.476298\n","[2500]\tvalid-rmse:0.476219\n","[3000]\tvalid-rmse:0.476174\n","[3500]\tvalid-rmse:0.476111\n","[4000]\tvalid-rmse:0.476008\n","[4500]\tvalid-rmse:0.47598\n","[5000]\tvalid-rmse:0.475947\n","[5500]\tvalid-rmse:0.475913\n","[6000]\tvalid-rmse:0.475843\n","[6500]\tvalid-rmse:0.475846\n","[7000]\tvalid-rmse:0.475848\n","Stopping. Best iteration:\n","[6059]\tvalid-rmse:0.475836\n","\n","best iteration: 6059\n","best score: 0.475836\n","Score for Model 5 fold 4: 1137.908844903594\n","Model 5 fold 4 finished in 2020.3709676265717\n","Score for model 5 is 1139.8248428250126\n","Socre for blended models is 1139.8248428250129\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2G2P2QPtzqZ3","colab_type":"code","outputId":"1011172f-1826-4057-868f-6953849798c3","executionInfo":{"status":"ok","timestamp":1585879989274,"user_tz":240,"elapsed":2541,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print (np.mean(blend_scores_xgb_ohe,axis=0))\n","np.savetxt(\"/content/drive/My Drive/Kaggle_Allstate/data/train_blend_x_xgb_ohe.csv\",train_blend_x_xgb_ohe, delimiter=\",\")\n","np.savetxt(\"/content/drive/My Drive/Kaggle_Allstate/data/test_blend_x_xgb_ohe.csv\",test_blend_x_xgb_ohe, delimiter=\",\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1139.82484283 1139.82484283 1139.82484283 1139.82484283 1139.82484283]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7D2e0as20JMU","colab_type":"code","outputId":"6b3cff78-f7f2-4cc9-f911-371b32a719d7","executionInfo":{"status":"ok","timestamp":1585883770277,"user_tz":240,"elapsed":373,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["blend_scores_xgb_ohe"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1138.55774648, 1138.55774648, 1138.55774648, 1138.55774648,\n","        1138.55774648],\n","       [1144.64372616, 1144.64372616, 1144.64372616, 1144.64372616,\n","        1144.64372616],\n","       [1138.18905375, 1138.18905375, 1138.18905375, 1138.18905375,\n","        1138.18905375],\n","       [1137.9088449 , 1137.9088449 , 1137.9088449 , 1137.9088449 ,\n","        1137.9088449 ]])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"NLuv56qBBWpA","colab_type":"text"},"source":["## LightGBM tuning \n","\n","### Manual tuning "]},{"cell_type":"code","metadata":{"id":"5lTy-CmACn_8","colab_type":"code","colab":{}},"source":["import lightgbm as lgb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmA12VeqBf9D","colab_type":"code","outputId":"f37857e9-316b-47d8-906b-82127a766a7c","executionInfo":{"status":"ok","timestamp":1585890712824,"user_tz":240,"elapsed":6895251,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import copy\n","default_lgb_params = {}\n","default_lgb_params[\"learning_rate\"] = 0.05\n","default_lgb_params[\"metric\"] = 'rmse'\n","default_lgb_params[\"bagging_freq\"] = 1\n","default_lgb_params[\"seed\"] = 1234\n","default_lgb_params[\"objective\"] = \"regression\"\n","\n","params_lgb_space = {}\n","params_lgb_space['num_leaves'] = [3, 7, 15, 31, 63, 127, 255]\n","params_lgb_space['max_depth'] = [3 ,4 ,5 ,6 ,7 ,8, -1]\n","params_lgb_space['min_gain_to_split'] = [0, 0.1, 0.3, 1, 1.5, 2, 3]\n","params_lgb_space['feature_fraction'] = [0.1, 0.3, 0.5, 0.7, 0.9]\n","params_lgb_space['bagging_fraction'] = [0.2, 0.4, 0.6, 0.8, 1]\n","params_lgb_space['min_sum_hessian_in_leaf'] = [1, 5, 10, 30, 100]\n","params_lgb_space['lambda_l2'] = [0, 0.01, 0.1, 1, 10, 100]\n","params_lgb_space['lambda_l1'] = [0, 0.01, 0.1, 1, 10, 100]\n","# params_lgb_space['objective'] = ['regression', 'regression_l1', 'poisson']\n","\n","\n","\n","greater_is_better = False\n","\n","best_lgb_params = copy.copy(default_lgb_params)\n","\n","for p in params_lgb_space:\n","    print (\"\\n Tuning parameter %s in %s\" % (p, params_lgb_space[p]))\n","\n","    params = best_lgb_params\n","    scores = []    \n","    for v in params_lgb_space[p]:\n","        print ('\\n    %s: %s' % (p, v), end=\"\\n\")\n","        params[p] = v\n","        lgb_cv = lgb.cv(params,\n","                lgb.Dataset(train_x,\n","                            label=train_y\n","                            ),\n","                num_boost_round=100000,\n","                nfold=kfolds,\n","                folds=skf.split(train_x,train_y),\n","                stratified=False,\n","                early_stopping_rounds=50,\n","                verbose_eval=500)\n","\n","        best_lgb_score = min(lgb_cv['rmse-mean'])\n","        best_lgb_iteration = len(lgb_cv['rmse-mean'])\n","        print (', best_score: %f, best_iteration: %d' % (best_lgb_score, best_lgb_iteration))\n","        scores.append([v, best_lgb_score])\n","    # best param value in the space\n","    best_param_value = sorted(scores, key=lambda x:x[1],reverse=greater_is_better)[0][0]\n","    best_param_score = sorted(scores, key=lambda x:x[1],reverse=greater_is_better)[0][1]\n","    best_lgb_params[p] = best_param_value\n","    print (\"Best %s is %s with a score of %f\" %(p, best_param_value, best_param_score))\n","\n","print ('\\n Best manually tuned parameters:', best_lgb_params)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," Tuning parameter num_leaves in [3, 7, 15, 31, 63, 127, 255]\n","\n","    num_leaves: 3\n","[500]\tcv_agg's rmse: 0.505839 + 0.00191511\n","[1000]\tcv_agg's rmse: 0.496659 + 0.00204289\n","[1500]\tcv_agg's rmse: 0.492759 + 0.00203624\n","[2000]\tcv_agg's rmse: 0.490481 + 0.00207569\n","[2500]\tcv_agg's rmse: 0.488903 + 0.00210415\n","[3000]\tcv_agg's rmse: 0.487686 + 0.00204864\n","[3500]\tcv_agg's rmse: 0.486779 + 0.00200334\n","[4000]\tcv_agg's rmse: 0.486039 + 0.00203188\n","[4500]\tcv_agg's rmse: 0.485444 + 0.00207037\n","[5000]\tcv_agg's rmse: 0.484937 + 0.0020953\n","[5500]\tcv_agg's rmse: 0.484493 + 0.00207589\n","[6000]\tcv_agg's rmse: 0.484114 + 0.00208844\n","[6500]\tcv_agg's rmse: 0.483753 + 0.00212901\n","[7000]\tcv_agg's rmse: 0.483364 + 0.00204097\n","[7500]\tcv_agg's rmse: 0.483133 + 0.00200727\n","[8000]\tcv_agg's rmse: 0.482911 + 0.00201319\n","[8500]\tcv_agg's rmse: 0.482682 + 0.00201121\n","[9000]\tcv_agg's rmse: 0.482531 + 0.00203356\n","[9500]\tcv_agg's rmse: 0.482406 + 0.00204363\n","[10000]\tcv_agg's rmse: 0.482228 + 0.00200524\n","[10500]\tcv_agg's rmse: 0.482078 + 0.00199551\n","[11000]\tcv_agg's rmse: 0.481984 + 0.00197472\n","[11500]\tcv_agg's rmse: 0.481894 + 0.00197177\n","[12000]\tcv_agg's rmse: 0.481772 + 0.00199116\n","[12500]\tcv_agg's rmse: 0.481682 + 0.00197262\n",", best_score: 0.481632, best_iteration: 12931\n","\n","    num_leaves: 7\n","[500]\tcv_agg's rmse: 0.487416 + 0.00195201\n","[1000]\tcv_agg's rmse: 0.483695 + 0.00206996\n","[1500]\tcv_agg's rmse: 0.482038 + 0.00218013\n","[2000]\tcv_agg's rmse: 0.480956 + 0.00223976\n","[2500]\tcv_agg's rmse: 0.480294 + 0.00222019\n","[3000]\tcv_agg's rmse: 0.479837 + 0.00223779\n","[3500]\tcv_agg's rmse: 0.47952 + 0.00227802\n","[4000]\tcv_agg's rmse: 0.479341 + 0.00230693\n","[4500]\tcv_agg's rmse: 0.47918 + 0.0022741\n",", best_score: 0.479142, best_iteration: 4668\n","\n","    num_leaves: 15\n","[500]\tcv_agg's rmse: 0.481276 + 0.00202375\n","[1000]\tcv_agg's rmse: 0.479579 + 0.00220934\n","[1500]\tcv_agg's rmse: 0.47884 + 0.00222082\n",", best_score: 0.478596, best_iteration: 1919\n","\n","    num_leaves: 31\n","[500]\tcv_agg's rmse: 0.478667 + 0.00206516\n","[1000]\tcv_agg's rmse: 0.478027 + 0.00207752\n",", best_score: 0.478000, best_iteration: 1038\n","\n","    num_leaves: 63\n","[500]\tcv_agg's rmse: 0.477513 + 0.00193051\n",", best_score: 0.477433, best_iteration: 604\n","\n","    num_leaves: 127\n",", best_score: 0.477256, best_iteration: 350\n","\n","    num_leaves: 255\n",", best_score: 0.477667, best_iteration: 200\n","Best num_leaves is 127 with a score of 0.477256\n","\n"," Tuning parameter max_depth in [3, 4, 5, 6, 7, 8, -1]\n","\n","    max_depth: 3\n","[500]\tcv_agg's rmse: 0.490105 + 0.00182257\n","[1000]\tcv_agg's rmse: 0.484823 + 0.00193696\n","[1500]\tcv_agg's rmse: 0.482908 + 0.00203894\n","[2000]\tcv_agg's rmse: 0.481879 + 0.00213632\n","[2500]\tcv_agg's rmse: 0.481124 + 0.002238\n","[3000]\tcv_agg's rmse: 0.480698 + 0.00223961\n","[3500]\tcv_agg's rmse: 0.480442 + 0.00221436\n","[4000]\tcv_agg's rmse: 0.480269 + 0.00217789\n",", best_score: 0.480240, best_iteration: 4064\n","\n","    max_depth: 4\n","[500]\tcv_agg's rmse: 0.484225 + 0.00199388\n","[1000]\tcv_agg's rmse: 0.480853 + 0.00217107\n","[1500]\tcv_agg's rmse: 0.479729 + 0.00224049\n","[2000]\tcv_agg's rmse: 0.479151 + 0.00228934\n","[2500]\tcv_agg's rmse: 0.478902 + 0.00225472\n",", best_score: 0.478891, best_iteration: 2521\n","\n","    max_depth: 5\n","[500]\tcv_agg's rmse: 0.481025 + 0.00216438\n","[1000]\tcv_agg's rmse: 0.47895 + 0.00236437\n","[1500]\tcv_agg's rmse: 0.478387 + 0.0024196\n",", best_score: 0.478340, best_iteration: 1567\n","\n","    max_depth: 6\n","[500]\tcv_agg's rmse: 0.479432 + 0.00216994\n","[1000]\tcv_agg's rmse: 0.478216 + 0.00232357\n",", best_score: 0.478117, best_iteration: 1137\n","\n","    max_depth: 7\n","[500]\tcv_agg's rmse: 0.478703 + 0.00220185\n",", best_score: 0.478104, best_iteration: 878\n","\n","    max_depth: 8\n","[500]\tcv_agg's rmse: 0.478247 + 0.0021354\n",", best_score: 0.478091, best_iteration: 707\n","\n","    max_depth: -1\n",", best_score: 0.477256, best_iteration: 350\n","Best max_depth is -1 with a score of 0.477256\n","\n"," Tuning parameter min_gain_to_split in [0, 0.1, 0.3, 1, 1.5, 2, 3]\n","\n","    min_gain_to_split: 0\n",", best_score: 0.477256, best_iteration: 350\n","\n","    min_gain_to_split: 0.1\n",", best_score: 0.477639, best_iteration: 250\n","\n","    min_gain_to_split: 0.3\n",", best_score: 0.477868, best_iteration: 263\n","\n","    min_gain_to_split: 1\n",", best_score: 0.479690, best_iteration: 182\n","\n","    min_gain_to_split: 1.5\n",", best_score: 0.480715, best_iteration: 174\n","\n","    min_gain_to_split: 2\n",", best_score: 0.481536, best_iteration: 213\n","\n","    min_gain_to_split: 3\n",", best_score: 0.483246, best_iteration: 163\n","Best min_gain_to_split is 0 with a score of 0.477256\n","\n"," Tuning parameter feature_fraction in [0.1, 0.3, 0.5, 0.7, 0.9]\n","\n","    feature_fraction: 0.1\n","[500]\tcv_agg's rmse: 0.476262 + 0.00217274\n",", best_score: 0.475902, best_iteration: 733\n","\n","    feature_fraction: 0.3\n","[500]\tcv_agg's rmse: 0.475479 + 0.00203787\n",", best_score: 0.475471, best_iteration: 473\n","\n","    feature_fraction: 0.5\n",", best_score: 0.476153, best_iteration: 315\n","\n","    feature_fraction: 0.7\n",", best_score: 0.476750, best_iteration: 327\n","\n","    feature_fraction: 0.9\n",", best_score: 0.477153, best_iteration: 377\n","Best feature_fraction is 0.3 with a score of 0.475471\n","\n"," Tuning parameter bagging_fraction in [0.2, 0.4, 0.6, 0.8, 1]\n","\n","    bagging_fraction: 0.2\n",", best_score: 0.479192, best_iteration: 254\n","\n","    bagging_fraction: 0.4\n",", best_score: 0.476703, best_iteration: 306\n","\n","    bagging_fraction: 0.6\n",", best_score: 0.475890, best_iteration: 426\n","\n","    bagging_fraction: 0.8\n",", best_score: 0.475493, best_iteration: 423\n","\n","    bagging_fraction: 1\n","[500]\tcv_agg's rmse: 0.475479 + 0.00203787\n",", best_score: 0.475471, best_iteration: 473\n","Best bagging_fraction is 1 with a score of 0.475471\n","\n"," Tuning parameter min_sum_hessian_in_leaf in [1, 5, 10, 30, 100]\n","\n","    min_sum_hessian_in_leaf: 1\n","[500]\tcv_agg's rmse: 0.475479 + 0.00203787\n",", best_score: 0.475471, best_iteration: 473\n","\n","    min_sum_hessian_in_leaf: 5\n","[500]\tcv_agg's rmse: 0.475479 + 0.00203787\n",", best_score: 0.475471, best_iteration: 473\n","\n","    min_sum_hessian_in_leaf: 10\n","[500]\tcv_agg's rmse: 0.475479 + 0.00203787\n",", best_score: 0.475471, best_iteration: 473\n","\n","    min_sum_hessian_in_leaf: 30\n",", best_score: 0.475284, best_iteration: 427\n","\n","    min_sum_hessian_in_leaf: 100\n","[500]\tcv_agg's rmse: 0.474967 + 0.0020686\n",", best_score: 0.474930, best_iteration: 468\n","Best min_sum_hessian_in_leaf is 100 with a score of 0.474930\n","\n"," Tuning parameter lambda_l2 in [0, 0.01, 0.1, 1, 10, 100]\n","\n","    lambda_l2: 0\n","[500]\tcv_agg's rmse: 0.474967 + 0.0020686\n",", best_score: 0.474930, best_iteration: 468\n","\n","    lambda_l2: 0.01\n","[500]\tcv_agg's rmse: 0.475089 + 0.00204093\n",", best_score: 0.475071, best_iteration: 476\n","\n","    lambda_l2: 0.1\n","[500]\tcv_agg's rmse: 0.474842 + 0.00210698\n",", best_score: 0.474831, best_iteration: 492\n","\n","    lambda_l2: 1\n",", best_score: 0.474953, best_iteration: 391\n","\n","    lambda_l2: 10\n","[500]\tcv_agg's rmse: 0.474984 + 0.001974\n",", best_score: 0.474954, best_iteration: 470\n","\n","    lambda_l2: 100\n","[500]\tcv_agg's rmse: 0.47504 + 0.00221182\n",", best_score: 0.475009, best_iteration: 590\n","Best lambda_l2 is 0.1 with a score of 0.474831\n","\n"," Tuning parameter lambda_l1 in [0, 0.01, 0.1, 1, 10, 100]\n","\n","    lambda_l1: 0\n","[500]\tcv_agg's rmse: 0.474842 + 0.00210698\n",", best_score: 0.474831, best_iteration: 492\n","\n","    lambda_l1: 0.01\n",", best_score: 0.474997, best_iteration: 389\n","\n","    lambda_l1: 0.1\n","[500]\tcv_agg's rmse: 0.475043 + 0.00210306\n",", best_score: 0.475011, best_iteration: 464\n","\n","    lambda_l1: 1\n","[500]\tcv_agg's rmse: 0.475147 + 0.00204797\n",", best_score: 0.475088, best_iteration: 462\n","\n","    lambda_l1: 10\n","[500]\tcv_agg's rmse: 0.47583 + 0.00197642\n",", best_score: 0.475820, best_iteration: 493\n","\n","    lambda_l1: 100\n","[500]\tcv_agg's rmse: 0.483239 + 0.0018279\n","[1000]\tcv_agg's rmse: 0.483125 + 0.00182915\n","[1500]\tcv_agg's rmse: 0.483125 + 0.00182915\n","[2000]\tcv_agg's rmse: 0.483125 + 0.00182915\n",", best_score: 0.483125, best_iteration: 2089\n","Best lambda_l1 is 0 with a score of 0.474831\n","\n"," Best manually tuned parameters: {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BbFB-d06Ck_A","colab_type":"code","outputId":"b0534513-c669-434e-9d3a-2b605b09240e","executionInfo":{"status":"ok","timestamp":1585890713243,"user_tz":240,"elapsed":401,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["best_param_value = sorted(scores, key=lambda x:x[1],reverse=greater_is_better)[0][0]\n","best_param_score = sorted(scores, key=lambda x:x[1],reverse=greater_is_better)[0][1]\n","best_lgb_params[p] = best_param_value\n","print (\"Best %s is %s with a score of %f\" %(p, best_param_value, best_param_score))\n","\n","print ('\\n Best manually tuned parameters:', best_lgb_params)\n","# Best manually tuned parameters: {'learning_rate': 0.05, 'metric': 'rmse', \n","# 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127,\n","# 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, \n","# 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best lambda_l1 is 0 with a score of 0.474831\n","\n"," Best manually tuned parameters: {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EJEPP-tl64re","colab_type":"code","colab":{}},"source":["best_lgb_params = {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bFZezWcNcKD9","colab_type":"text"},"source":["### Automated tuning\n"]},{"cell_type":"code","metadata":{"id":"NcNKCiRDcEEK","colab_type":"code","outputId":"b0068823-4a50-4ac5-f3b3-e444200b33cd","executionInfo":{"status":"ok","timestamp":1585930708687,"user_tz":240,"elapsed":6468871,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def lgb_evaluate(\n","    num_leaves,\n","    max_depth,\n","    min_sum_hessian_in_leaf,\n","    min_gain_to_split,\n","    feature_fraction,\n","    bagging_fraction,\n","    lambda_l2,\n","    lambda_l1\n","):\n","    params = dict()\n","    params['objective'] = 'regression'\n","    params['learning_rate'] = 0.05\n","    params['seed'] = 1234\n","    params['num_leaves'] = int(num_leaves)\n","    params['max_depth'] = int(max_depth)\n","    params['min_sum_hessian_in_leaf'] = int(min_sum_hessian_in_leaf)\n","    params['min_gain_to_split'] = min_gain_to_split\n","    params['feature_fraction'] = feature_fraction\n","    params['bagging_fraction'] = bagging_fraction\n","    params['bagging_freq'] = 1\n","    params['lambda_l2'] = lambda_l2\n","    params['lambda_l1'] = lambda_l1\n","    params[\"metric\"] = 'rmse'\n","\n","    lgb_cv = lgb.cv(params,\n","                    lgb.Dataset(train_x,\n","                                label=train_y\n","                                ),\n","                    num_boost_round=100000,\n","                    nfold=kfolds,\n","                    folds=skf.split(train_x, train_y),\n","                    early_stopping_rounds=50,\n","                    verbose_eval=500)\n","\n","    best_lgb_score = min(lgb_cv['rmse-mean'])\n","    best_lgb_iteration = len(lgb_cv['rmse-mean'])\n","    print(', best_score: %f, best_iteration: %d' %\n","          (best_lgb_score, best_lgb_iteration))\n","\n","    return -best_lgb_score\n","\n","\n","lgb_BO = BayesianOptimization(lgb_evaluate,\n","                              {\n","                                  'num_leaves': (7, 31),\n","                                  'max_depth': (7, 31),\n","                                  'min_sum_hessian_in_leaf': (0, 2),\n","                                  'min_gain_to_split': (0, 5),\n","                                  'feature_fraction': (0.3, 0.6),\n","                                  'bagging_fraction': (0.9, 1),\n","                                  'lambda_l2': (0, 1),\n","                                  'lambda_l1': (0, 1)\n","                              }\n","                              )\n","\n","lgb_BO.maximize(init_points=5, n_iter=40)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | max_depth | min_ga... | min_su... | num_le... |\n","-------------------------------------------------------------------------------------------------------------------------\n",", best_score: 0.483431, best_iteration: 428\n","| \u001b[0m 1       \u001b[0m | \u001b[0m-0.4834  \u001b[0m | \u001b[0m 0.9261  \u001b[0m | \u001b[0m 0.3936  \u001b[0m | \u001b[0m 0.4878  \u001b[0m | \u001b[0m 0.5012  \u001b[0m | \u001b[0m 13.61   \u001b[0m | \u001b[0m 1.891   \u001b[0m | \u001b[0m 0.4009  \u001b[0m | \u001b[0m 19.77   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.484975 + 0.00218251\n",", best_score: 0.483466, best_iteration: 845\n","| \u001b[0m 2       \u001b[0m | \u001b[0m-0.4835  \u001b[0m | \u001b[0m 0.9077  \u001b[0m | \u001b[0m 0.5601  \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.5944  \u001b[0m | \u001b[0m 28.85   \u001b[0m | \u001b[0m 0.9988  \u001b[0m | \u001b[0m 0.4624  \u001b[0m | \u001b[0m 9.263   \u001b[0m |\n",", best_score: 0.486230, best_iteration: 428\n","| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4862  \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 0.5678  \u001b[0m | \u001b[0m 0.9204  \u001b[0m | \u001b[0m 0.6542  \u001b[0m | \u001b[0m 22.83   \u001b[0m | \u001b[0m 2.719   \u001b[0m | \u001b[0m 0.3478  \u001b[0m | \u001b[0m 11.49   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.485547 + 0.00202264\n",", best_score: 0.485547, best_iteration: 465\n","| \u001b[0m 4       \u001b[0m | \u001b[0m-0.4855  \u001b[0m | \u001b[0m 0.9654  \u001b[0m | \u001b[0m 0.3236  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.9529  \u001b[0m | \u001b[0m 9.554   \u001b[0m | \u001b[0m 2.589   \u001b[0m | \u001b[0m 1.307   \u001b[0m | \u001b[0m 12.87   \u001b[0m |\n",", best_score: 0.485808, best_iteration: 263\n","| \u001b[0m 5       \u001b[0m | \u001b[0m-0.4858  \u001b[0m | \u001b[0m 0.9624  \u001b[0m | \u001b[0m 0.4774  \u001b[0m | \u001b[0m 0.9284  \u001b[0m | \u001b[0m 0.6479  \u001b[0m | \u001b[0m 22.8    \u001b[0m | \u001b[0m 4.36    \u001b[0m | \u001b[0m 0.6454  \u001b[0m | \u001b[0m 28.53   \u001b[0m |\n",", best_score: 0.484960, best_iteration: 301\n","| \u001b[0m 6       \u001b[0m | \u001b[0m-0.485   \u001b[0m | \u001b[0m 0.9014  \u001b[0m | \u001b[0m 0.5056  \u001b[0m | \u001b[0m 0.5878  \u001b[0m | \u001b[0m 0.1629  \u001b[0m | \u001b[0m 30.86   \u001b[0m | \u001b[0m 3.777   \u001b[0m | \u001b[0m 1.74    \u001b[0m | \u001b[0m 30.82   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.48768 + 0.00196954\n",", best_score: 0.486156, best_iteration: 715\n","| \u001b[0m 7       \u001b[0m | \u001b[0m-0.4862  \u001b[0m | \u001b[0m 0.9902  \u001b[0m | \u001b[0m 0.4644  \u001b[0m | \u001b[0m 0.9907  \u001b[0m | \u001b[0m 0.3923  \u001b[0m | \u001b[0m 7.272   \u001b[0m | \u001b[0m 1.504   \u001b[0m | \u001b[0m 0.1974  \u001b[0m | \u001b[0m 7.194   \u001b[0m |\n",", best_score: 0.485990, best_iteration: 294\n","| \u001b[0m 8       \u001b[0m | \u001b[0m-0.486   \u001b[0m | \u001b[0m 0.9403  \u001b[0m | \u001b[0m 0.4461  \u001b[0m | \u001b[0m 0.5177  \u001b[0m | \u001b[0m 0.7123  \u001b[0m | \u001b[0m 30.79   \u001b[0m | \u001b[0m 4.654   \u001b[0m | \u001b[0m 1.248   \u001b[0m | \u001b[0m 30.95   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.487747 + 0.00196508\n",", best_score: 0.486685, best_iteration: 706\n","| \u001b[0m 9       \u001b[0m | \u001b[0m-0.4867  \u001b[0m | \u001b[0m 0.9405  \u001b[0m | \u001b[0m 0.4527  \u001b[0m | \u001b[0m 0.4456  \u001b[0m | \u001b[0m 0.008011\u001b[0m | \u001b[0m 30.89   \u001b[0m | \u001b[0m 1.998   \u001b[0m | \u001b[0m 0.3074  \u001b[0m | \u001b[0m 7.214   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.480955 + 0.00197033\n",", best_score: 0.480948, best_iteration: 530\n","| \u001b[95m 10      \u001b[0m | \u001b[95m-0.4809  \u001b[0m | \u001b[95m 0.9581  \u001b[0m | \u001b[95m 0.5356  \u001b[0m | \u001b[95m 0.4725  \u001b[0m | \u001b[95m 0.5324  \u001b[0m | \u001b[95m 7.001   \u001b[0m | \u001b[95m 1.027   \u001b[0m | \u001b[95m 0.6181  \u001b[0m | \u001b[95m 30.77   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478628 + 0.00207093\n","[1000]\tcv_agg's rmse: 0.478032 + 0.00210391\n",", best_score: 0.477988, best_iteration: 1147\n","| \u001b[95m 11      \u001b[0m | \u001b[95m-0.478   \u001b[0m | \u001b[95m 0.951   \u001b[0m | \u001b[95m 0.3179  \u001b[0m | \u001b[95m 0.03006 \u001b[0m | \u001b[95m 0.9615  \u001b[0m | \u001b[95m 29.92   \u001b[0m | \u001b[95m 0.2455  \u001b[0m | \u001b[95m 0.1032  \u001b[0m | \u001b[95m 30.89   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.47853 + 0.00202927\n","[1000]\tcv_agg's rmse: 0.477951 + 0.00203791\n",", best_score: 0.477905, best_iteration: 1169\n","| \u001b[95m 12      \u001b[0m | \u001b[95m-0.4779  \u001b[0m | \u001b[95m 0.9813  \u001b[0m | \u001b[95m 0.5303  \u001b[0m | \u001b[95m 0.2129  \u001b[0m | \u001b[95m 0.5254  \u001b[0m | \u001b[95m 28.98   \u001b[0m | \u001b[95m 0.08962 \u001b[0m | \u001b[95m 1.861   \u001b[0m | \u001b[95m 30.53   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478031 + 0.00201668\n","[1000]\tcv_agg's rmse: 0.477018 + 0.00204954\n","[1500]\tcv_agg's rmse: 0.476869 + 0.00206208\n",", best_score: 0.476846, best_iteration: 1451\n","| \u001b[95m 13      \u001b[0m | \u001b[95m-0.4768  \u001b[0m | \u001b[95m 0.9631  \u001b[0m | \u001b[95m 0.4314  \u001b[0m | \u001b[95m 0.9606  \u001b[0m | \u001b[95m 0.7491  \u001b[0m | \u001b[95m 29.39   \u001b[0m | \u001b[95m 0.02831 \u001b[0m | \u001b[95m 1.966   \u001b[0m | \u001b[95m 30.17   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477967 + 0.00205205\n","[1000]\tcv_agg's rmse: 0.47697 + 0.00206197\n","[1500]\tcv_agg's rmse: 0.4768 + 0.00205582\n",", best_score: 0.476774, best_iteration: 1454\n","| \u001b[95m 14      \u001b[0m | \u001b[95m-0.4768  \u001b[0m | \u001b[95m 0.9113  \u001b[0m | \u001b[95m 0.4049  \u001b[0m | \u001b[95m 0.01607 \u001b[0m | \u001b[95m 0.4344  \u001b[0m | \u001b[95m 29.46   \u001b[0m | \u001b[95m 0.02241 \u001b[0m | \u001b[95m 1.85    \u001b[0m | \u001b[95m 30.67   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478366 + 0.0020022\n","[1000]\tcv_agg's rmse: 0.477691 + 0.00198557\n",", best_score: 0.477570, best_iteration: 1307\n","| \u001b[0m 15      \u001b[0m | \u001b[0m-0.4776  \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 0.3413  \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 0.9494  \u001b[0m | \u001b[0m 13.63   \u001b[0m | \u001b[0m 0.1069  \u001b[0m | \u001b[0m 1.989   \u001b[0m | \u001b[0m 30.85   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.47813 + 0.00213164\n","[1000]\tcv_agg's rmse: 0.477386 + 0.00203485\n",", best_score: 0.477379, best_iteration: 990\n","| \u001b[0m 16      \u001b[0m | \u001b[0m-0.4774  \u001b[0m | \u001b[0m 0.9794  \u001b[0m | \u001b[0m 0.3537  \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 0.008187\u001b[0m | \u001b[0m 29.6    \u001b[0m | \u001b[0m 0.08501 \u001b[0m | \u001b[0m 0.4172  \u001b[0m | \u001b[0m 30.91   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477819 + 0.00203971\n","[1000]\tcv_agg's rmse: 0.476971 + 0.00207411\n",", best_score: 0.476968, best_iteration: 994\n","| \u001b[0m 17      \u001b[0m | \u001b[0m-0.477   \u001b[0m | \u001b[0m 0.9281  \u001b[0m | \u001b[0m 0.3085  \u001b[0m | \u001b[0m 0.927   \u001b[0m | \u001b[0m 0.1173  \u001b[0m | \u001b[0m 28.99   \u001b[0m | \u001b[0m 0.05304 \u001b[0m | \u001b[0m 1.875   \u001b[0m | \u001b[0m 30.74   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478327 + 0.00215131\n","[1000]\tcv_agg's rmse: 0.477603 + 0.00216365\n",", best_score: 0.477484, best_iteration: 1232\n","| \u001b[0m 18      \u001b[0m | \u001b[0m-0.4775  \u001b[0m | \u001b[0m 0.9928  \u001b[0m | \u001b[0m 0.3215  \u001b[0m | \u001b[0m 0.5212  \u001b[0m | \u001b[0m 0.8991  \u001b[0m | \u001b[0m 30.87   \u001b[0m | \u001b[0m 0.1131  \u001b[0m | \u001b[0m 0.8449  \u001b[0m | \u001b[0m 30.93   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478223 + 0.00205472\n","[1000]\tcv_agg's rmse: 0.477672 + 0.0020776\n",", best_score: 0.477666, best_iteration: 996\n","| \u001b[0m 19      \u001b[0m | \u001b[0m-0.4777  \u001b[0m | \u001b[0m 0.9366  \u001b[0m | \u001b[0m 0.5685  \u001b[0m | \u001b[0m 0.9218  \u001b[0m | \u001b[0m 0.7257  \u001b[0m | \u001b[0m 22.77   \u001b[0m | \u001b[0m 0.1412  \u001b[0m | \u001b[0m 1.795   \u001b[0m | \u001b[0m 30.9    \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478053 + 0.00187449\n","[1000]\tcv_agg's rmse: 0.477029 + 0.0018716\n","[1500]\tcv_agg's rmse: 0.476736 + 0.00197226\n",", best_score: 0.476706, best_iteration: 1542\n","| \u001b[95m 20      \u001b[0m | \u001b[95m-0.4767  \u001b[0m | \u001b[95m 0.9008  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.07523 \u001b[0m | \u001b[95m 0.9737  \u001b[0m | \u001b[95m 30.98   \u001b[0m | \u001b[95m 0.002939\u001b[0m | \u001b[95m 0.7425  \u001b[0m | \u001b[95m 29.54   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478426 + 0.00206244\n",", best_score: 0.477799, best_iteration: 914\n","| \u001b[0m 21      \u001b[0m | \u001b[0m-0.4778  \u001b[0m | \u001b[0m 0.97    \u001b[0m | \u001b[0m 0.5522  \u001b[0m | \u001b[0m 0.7442  \u001b[0m | \u001b[0m 0.9597  \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.1253  \u001b[0m | \u001b[0m 1.777   \u001b[0m | \u001b[0m 30.76   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477985 + 0.00209456\n","[1000]\tcv_agg's rmse: 0.47704 + 0.00213338\n",", best_score: 0.476891, best_iteration: 1207\n","| \u001b[0m 22      \u001b[0m | \u001b[0m-0.4769  \u001b[0m | \u001b[0m 0.952   \u001b[0m | \u001b[0m 0.4331  \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 28.66   \u001b[0m | \u001b[0m 0.0235  \u001b[0m | \u001b[0m 0.9207  \u001b[0m | \u001b[0m 30.69   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478298 + 0.0020962\n","[1000]\tcv_agg's rmse: 0.477576 + 0.00207497\n",", best_score: 0.477532, best_iteration: 1220\n","| \u001b[0m 23      \u001b[0m | \u001b[0m-0.4775  \u001b[0m | \u001b[0m 0.9712  \u001b[0m | \u001b[0m 0.3048  \u001b[0m | \u001b[0m 0.9601  \u001b[0m | \u001b[0m 0.9782  \u001b[0m | \u001b[0m 29.4    \u001b[0m | \u001b[0m 0.1818  \u001b[0m | \u001b[0m 0.1402  \u001b[0m | \u001b[0m 30.76   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478316 + 0.00195452\n","[1000]\tcv_agg's rmse: 0.477415 + 0.00194445\n",", best_score: 0.477251, best_iteration: 1307\n","| \u001b[0m 24      \u001b[0m | \u001b[0m-0.4773  \u001b[0m | \u001b[0m 0.987   \u001b[0m | \u001b[0m 0.5303  \u001b[0m | \u001b[0m 0.08669 \u001b[0m | \u001b[0m 0.4414  \u001b[0m | \u001b[0m 23.56   \u001b[0m | \u001b[0m 0.01993 \u001b[0m | \u001b[0m 1.64    \u001b[0m | \u001b[0m 30.7    \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477943 + 0.00198718\n","[1000]\tcv_agg's rmse: 0.476815 + 0.00195626\n",", best_score: 0.476492, best_iteration: 1446\n","| \u001b[95m 25      \u001b[0m | \u001b[95m-0.4765  \u001b[0m | \u001b[95m 0.911   \u001b[0m | \u001b[95m 0.3271  \u001b[0m | \u001b[95m 0.369   \u001b[0m | \u001b[95m 0.9573  \u001b[0m | \u001b[95m 28.97   \u001b[0m | \u001b[95m 0.01102 \u001b[0m | \u001b[95m 1.448   \u001b[0m | \u001b[95m 30.68   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478412 + 0.00195375\n","[1000]\tcv_agg's rmse: 0.477685 + 0.00201902\n",", best_score: 0.477582, best_iteration: 1369\n","| \u001b[0m 26      \u001b[0m | \u001b[0m-0.4776  \u001b[0m | \u001b[0m 0.9742  \u001b[0m | \u001b[0m 0.3489  \u001b[0m | \u001b[0m 0.1747  \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 29.87   \u001b[0m | \u001b[0m 0.1218  \u001b[0m | \u001b[0m 1.88    \u001b[0m | \u001b[0m 30.04   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477967 + 0.00208015\n","[1000]\tcv_agg's rmse: 0.476931 + 0.00206783\n",", best_score: 0.476694, best_iteration: 1300\n","| \u001b[0m 27      \u001b[0m | \u001b[0m-0.4767  \u001b[0m | \u001b[0m 0.9746  \u001b[0m | \u001b[0m 0.3075  \u001b[0m | \u001b[0m 0.0425  \u001b[0m | \u001b[0m 0.009317\u001b[0m | \u001b[0m 27.84   \u001b[0m | \u001b[0m 0.01203 \u001b[0m | \u001b[0m 0.4533  \u001b[0m | \u001b[0m 30.86   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.47816 + 0.00204751\n","[1000]\tcv_agg's rmse: 0.477265 + 0.00202887\n",", best_score: 0.477062, best_iteration: 1245\n","| \u001b[0m 28      \u001b[0m | \u001b[0m-0.4771  \u001b[0m | \u001b[0m 0.9738  \u001b[0m | \u001b[0m 0.5704  \u001b[0m | \u001b[0m 0.8343  \u001b[0m | \u001b[0m 0.3838  \u001b[0m | \u001b[0m 29.41   \u001b[0m | \u001b[0m 0.01852 \u001b[0m | \u001b[0m 1.966   \u001b[0m | \u001b[0m 29.95   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477939 + 0.00212018\n","[1000]\tcv_agg's rmse: 0.476846 + 0.00206678\n",", best_score: 0.476536, best_iteration: 1425\n","| \u001b[0m 29      \u001b[0m | \u001b[0m-0.4765  \u001b[0m | \u001b[0m 0.9782  \u001b[0m | \u001b[0m 0.3959  \u001b[0m | \u001b[0m 0.7461  \u001b[0m | \u001b[0m 0.9615  \u001b[0m | \u001b[0m 30.53   \u001b[0m | \u001b[0m 0.01126 \u001b[0m | \u001b[0m 0.4636  \u001b[0m | \u001b[0m 30.1    \u001b[0m |\n","[500]\tcv_agg's rmse: 0.47811 + 0.00215093\n","[1000]\tcv_agg's rmse: 0.477151 + 0.00212837\n",", best_score: 0.476910, best_iteration: 1411\n","| \u001b[0m 30      \u001b[0m | \u001b[0m-0.4769  \u001b[0m | \u001b[0m 0.9585  \u001b[0m | \u001b[0m 0.3476  \u001b[0m | \u001b[0m 0.0191  \u001b[0m | \u001b[0m 0.1886  \u001b[0m | \u001b[0m 30.92   \u001b[0m | \u001b[0m 0.01648 \u001b[0m | \u001b[0m 0.4819  \u001b[0m | \u001b[0m 30.28   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478046 + 0.00203777\n","[1000]\tcv_agg's rmse: 0.476999 + 0.00198235\n",", best_score: 0.476867, best_iteration: 1308\n","| \u001b[0m 31      \u001b[0m | \u001b[0m-0.4769  \u001b[0m | \u001b[0m 0.9154  \u001b[0m | \u001b[0m 0.3336  \u001b[0m | \u001b[0m 0.4607  \u001b[0m | \u001b[0m 0.8478  \u001b[0m | \u001b[0m 30.93   \u001b[0m | \u001b[0m 0.03151 \u001b[0m | \u001b[0m 1.401   \u001b[0m | \u001b[0m 30.37   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478254 + 0.0020124\n","[1000]\tcv_agg's rmse: 0.477493 + 0.00209222\n",", best_score: 0.477401, best_iteration: 1230\n","| \u001b[0m 32      \u001b[0m | \u001b[0m-0.4774  \u001b[0m | \u001b[0m 0.9748  \u001b[0m | \u001b[0m 0.5815  \u001b[0m | \u001b[0m 0.949   \u001b[0m | \u001b[0m 0.9605  \u001b[0m | \u001b[0m 27.23   \u001b[0m | \u001b[0m 0.06552 \u001b[0m | \u001b[0m 0.2033  \u001b[0m | \u001b[0m 29.43   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477854 + 0.00199121\n","[1000]\tcv_agg's rmse: 0.476989 + 0.00196264\n",", best_score: 0.476918, best_iteration: 1135\n","| \u001b[0m 33      \u001b[0m | \u001b[0m-0.4769  \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.5555  \u001b[0m | \u001b[0m 0.7479  \u001b[0m | \u001b[0m 0.6369  \u001b[0m | \u001b[0m 30.08   \u001b[0m | \u001b[0m 0.02907 \u001b[0m | \u001b[0m 0.04765 \u001b[0m | \u001b[0m 30.91   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478274 + 0.00195292\n","[1000]\tcv_agg's rmse: 0.477631 + 0.00201287\n",", best_score: 0.477583, best_iteration: 1154\n","| \u001b[0m 34      \u001b[0m | \u001b[0m-0.4776  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.4982  \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.8102  \u001b[0m | \u001b[0m 29.95   \u001b[0m | \u001b[0m 0.09644 \u001b[0m | \u001b[0m 1.831   \u001b[0m | \u001b[0m 30.74   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478298 + 0.00194955\n","[1000]\tcv_agg's rmse: 0.477496 + 0.00196519\n",", best_score: 0.477466, best_iteration: 1077\n","| \u001b[0m 35      \u001b[0m | \u001b[0m-0.4775  \u001b[0m | \u001b[0m 0.9396  \u001b[0m | \u001b[0m 0.4223  \u001b[0m | \u001b[0m 0.9837  \u001b[0m | \u001b[0m 0.05902 \u001b[0m | \u001b[0m 27.5    \u001b[0m | \u001b[0m 0.07385 \u001b[0m | \u001b[0m 0.7005  \u001b[0m | \u001b[0m 30.94   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478033 + 0.00201549\n","[1000]\tcv_agg's rmse: 0.477112 + 0.00202094\n",", best_score: 0.476952, best_iteration: 1272\n","| \u001b[0m 36      \u001b[0m | \u001b[0m-0.477   \u001b[0m | \u001b[0m 0.9615  \u001b[0m | \u001b[0m 0.5439  \u001b[0m | \u001b[0m 0.07842 \u001b[0m | \u001b[0m 0.7079  \u001b[0m | \u001b[0m 24.52   \u001b[0m | \u001b[0m 0.001787\u001b[0m | \u001b[0m 0.2838  \u001b[0m | \u001b[0m 30.43   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478249 + 0.00215797\n","[1000]\tcv_agg's rmse: 0.477554 + 0.00215183\n",", best_score: 0.477541, best_iteration: 1033\n","| \u001b[0m 37      \u001b[0m | \u001b[0m-0.4775  \u001b[0m | \u001b[0m 0.9149  \u001b[0m | \u001b[0m 0.4142  \u001b[0m | \u001b[0m 0.1214  \u001b[0m | \u001b[0m 0.7694  \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 0.004251\u001b[0m | \u001b[0m 30.83   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477872 + 0.00214276\n","[1000]\tcv_agg's rmse: 0.476872 + 0.00213132\n",", best_score: 0.476743, best_iteration: 1221\n","| \u001b[0m 38      \u001b[0m | \u001b[0m-0.4767  \u001b[0m | \u001b[0m 0.925   \u001b[0m | \u001b[0m 0.3989  \u001b[0m | \u001b[0m 0.696   \u001b[0m | \u001b[0m 0.08697 \u001b[0m | \u001b[0m 28.3    \u001b[0m | \u001b[0m 0.02629 \u001b[0m | \u001b[0m 0.3559  \u001b[0m | \u001b[0m 30.95   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478372 + 0.00207873\n","[1000]\tcv_agg's rmse: 0.477677 + 0.00210933\n",", best_score: 0.477613, best_iteration: 1139\n","| \u001b[0m 39      \u001b[0m | \u001b[0m-0.4776  \u001b[0m | \u001b[0m 0.9642  \u001b[0m | \u001b[0m 0.4452  \u001b[0m | \u001b[0m 0.3145  \u001b[0m | \u001b[0m 0.1093  \u001b[0m | \u001b[0m 29.19   \u001b[0m | \u001b[0m 0.1034  \u001b[0m | \u001b[0m 0.01353 \u001b[0m | \u001b[0m 30.91   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478018 + 0.00199847\n","[1000]\tcv_agg's rmse: 0.477124 + 0.00204944\n",", best_score: 0.476926, best_iteration: 1343\n","| \u001b[0m 40      \u001b[0m | \u001b[0m-0.4769  \u001b[0m | \u001b[0m 0.9199  \u001b[0m | \u001b[0m 0.4664  \u001b[0m | \u001b[0m 0.02397 \u001b[0m | \u001b[0m 0.005368\u001b[0m | \u001b[0m 22.31   \u001b[0m | \u001b[0m 0.01587 \u001b[0m | \u001b[0m 1.95    \u001b[0m | \u001b[0m 30.59   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478277 + 0.00207261\n","[1000]\tcv_agg's rmse: 0.47692 + 0.00202217\n","[1500]\tcv_agg's rmse: 0.476656 + 0.0020679\n",", best_score: 0.476643, best_iteration: 1578\n","| \u001b[0m 41      \u001b[0m | \u001b[0m-0.4766  \u001b[0m | \u001b[0m 0.9176  \u001b[0m | \u001b[0m 0.3827  \u001b[0m | \u001b[0m 0.8979  \u001b[0m | \u001b[0m 0.9905  \u001b[0m | \u001b[0m 8.366   \u001b[0m | \u001b[0m 0.01872 \u001b[0m | \u001b[0m 0.535   \u001b[0m | \u001b[0m 30.79   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478434 + 0.00215442\n","[1000]\tcv_agg's rmse: 0.477629 + 0.00213772\n",", best_score: 0.477551, best_iteration: 1244\n","| \u001b[0m 42      \u001b[0m | \u001b[0m-0.4776  \u001b[0m | \u001b[0m 0.9103  \u001b[0m | \u001b[0m 0.3322  \u001b[0m | \u001b[0m 0.1427  \u001b[0m | \u001b[0m 0.1395  \u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 0.1066  \u001b[0m | \u001b[0m 1.936   \u001b[0m | \u001b[0m 30.57   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477865 + 0.00215376\n","[1000]\tcv_agg's rmse: 0.476887 + 0.00213181\n","[1500]\tcv_agg's rmse: 0.476587 + 0.00205334\n",", best_score: 0.476537, best_iteration: 1713\n","| \u001b[0m 43      \u001b[0m | \u001b[0m-0.4765  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.3705  \u001b[0m | \u001b[0m 0.498   \u001b[0m | \u001b[0m 0.995   \u001b[0m | \u001b[0m 23.93   \u001b[0m | \u001b[0m 0.005964\u001b[0m | \u001b[0m 0.09081 \u001b[0m | \u001b[0m 30.15   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.477882 + 0.00203879\n","[1000]\tcv_agg's rmse: 0.476876 + 0.00202547\n",", best_score: 0.476777, best_iteration: 1150\n","| \u001b[0m 44      \u001b[0m | \u001b[0m-0.4768  \u001b[0m | \u001b[0m 0.928   \u001b[0m | \u001b[0m 0.3448  \u001b[0m | \u001b[0m 0.5321  \u001b[0m | \u001b[0m 0.9245  \u001b[0m | \u001b[0m 25.88   \u001b[0m | \u001b[0m 0.02419 \u001b[0m | \u001b[0m 0.07658 \u001b[0m | \u001b[0m 30.55   \u001b[0m |\n","[500]\tcv_agg's rmse: 0.478081 + 0.00204104\n","[1000]\tcv_agg's rmse: 0.477223 + 0.00198756\n",", best_score: 0.477142, best_iteration: 1146\n","| \u001b[0m 45      \u001b[0m | \u001b[0m-0.4771  \u001b[0m | \u001b[0m 0.9194  \u001b[0m | \u001b[0m 0.4734  \u001b[0m | \u001b[0m 0.06538 \u001b[0m | \u001b[0m 0.9798  \u001b[0m | \u001b[0m 14.54   \u001b[0m | \u001b[0m 0.02572 \u001b[0m | \u001b[0m 1.96    \u001b[0m | \u001b[0m 30.03   \u001b[0m |\n","=========================================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pQt_wSjJdnR8","colab_type":"code","colab":{}},"source":["# lgb_BO_scores = pd.DataFrame(lgb_BO.res['all']['params'])\n","# lgb_BO_scores['score'] = pd.DataFrame(lgb_BO.res['all']['values'])\n","# lgb_BO_scores = lgb_BO_scores.sort_values(by='score',ascending=False)\n","\n","# lgb_BO_scores.to_csv(\"../python/tuned_lgb_parameters.csv\", index=False)\n","# lgb_BO_scores.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vab0i8qvdU41","colab_type":"code","outputId":"07cda647-7754-4584-cd51-90350034d58a","executionInfo":{"status":"ok","timestamp":1585930979914,"user_tz":240,"elapsed":546,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["lgb_BO_scores = pd.DataFrame()\n","for dic in lgb_BO.res:\n","  param = dic['params']\n","  param = pd.DataFrame([param])\n","  lgb_BO_scores = pd.concat([lgb_BO_scores, param], ignore_index=True)\n","\n","lgb_BO_scores['score'] = pd.DataFrame(lgb_BO.res)['target']\n","lgb_BO_scores = lgb_BO_scores.sort_values(by='score',ascending=False)\n","lgb_BO_scores.to_csv(\"/content/drive/My Drive/Kaggle_Allstate/data/tuned_lgb_parameters.csv\", index=False)\n","lgb_BO_scores.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bagging_fraction</th>\n","      <th>feature_fraction</th>\n","      <th>lambda_l1</th>\n","      <th>lambda_l2</th>\n","      <th>max_depth</th>\n","      <th>min_gain_to_split</th>\n","      <th>min_sum_hessian_in_leaf</th>\n","      <th>num_leaves</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24</th>\n","      <td>0.910978</td>\n","      <td>0.327053</td>\n","      <td>0.368974</td>\n","      <td>0.957313</td>\n","      <td>28.970349</td>\n","      <td>0.011020</td>\n","      <td>1.448205</td>\n","      <td>30.684386</td>\n","      <td>-0.476492</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.978161</td>\n","      <td>0.395853</td>\n","      <td>0.746052</td>\n","      <td>0.961526</td>\n","      <td>30.533542</td>\n","      <td>0.011259</td>\n","      <td>0.463573</td>\n","      <td>30.103439</td>\n","      <td>-0.476536</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.948743</td>\n","      <td>0.370517</td>\n","      <td>0.498037</td>\n","      <td>0.994976</td>\n","      <td>23.930208</td>\n","      <td>0.005964</td>\n","      <td>0.090805</td>\n","      <td>30.154232</td>\n","      <td>-0.476537</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.917562</td>\n","      <td>0.382699</td>\n","      <td>0.897928</td>\n","      <td>0.990475</td>\n","      <td>8.365717</td>\n","      <td>0.018716</td>\n","      <td>0.535025</td>\n","      <td>30.790027</td>\n","      <td>-0.476643</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.974626</td>\n","      <td>0.307545</td>\n","      <td>0.042501</td>\n","      <td>0.009317</td>\n","      <td>27.842715</td>\n","      <td>0.012032</td>\n","      <td>0.453331</td>\n","      <td>30.864902</td>\n","      <td>-0.476694</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    bagging_fraction  feature_fraction  ...  num_leaves     score\n","24          0.910978          0.327053  ...   30.684386 -0.476492\n","28          0.978161          0.395853  ...   30.103439 -0.476536\n","42          0.948743          0.370517  ...   30.154232 -0.476537\n","40          0.917562          0.382699  ...   30.790027 -0.476643\n","26          0.974626          0.307545  ...   30.864902 -0.476694\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"MPicmzw8eYQQ","colab_type":"code","outputId":"94162328-acb7-4098-925f-9bb6fbecae21","executionInfo":{"status":"ok","timestamp":1585931914997,"user_tz":240,"elapsed":847812,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["params = lgb_BO_scores.iloc[0].to_dict()\n","best_auto_lgb_params = dict()\n","best_auto_lgb_params['objective'] = 'regression'\n","best_auto_lgb_params[\"metric\"] = 'rmse'\n","best_auto_lgb_params['learning_rate'] = 0.01 # Smaller learning rate\n","best_auto_lgb_params['num_leaves'] = int(params['num_leaves'])    \n","best_auto_lgb_params['max_depth'] = int(params['max_depth'])    \n","best_auto_lgb_params['min_sum_hessian_in_leaf'] = int(params['min_sum_hessian_in_leaf'])\n","best_auto_lgb_params['min_gain_to_split'] = params['min_gain_to_split']     \n","best_auto_lgb_params['feature_fraction'] = params['feature_fraction']\n","best_auto_lgb_params['bagging_fraction'] = params['bagging_fraction']\n","best_auto_lgb_params['bagging_freq'] = 1\n","best_auto_lgb_params['lambda_l2'] = params['lambda_l2']\n","best_auto_lgb_params['lambda_l1'] = params['lambda_l1']\n","best_auto_lgb_params['seed'] = 1234\n","\n","\n","print (best_auto_lgb_params)\n","\n","\n","lgb_cv = lgb.cv(best_auto_lgb_params,\n","            lgb.Dataset(train_x,\n","                        label=train_y\n","                        ),\n","            num_boost_round=100000,\n","            nfold=kfolds,\n","            folds=skf.split(train_x,train_y),\n","            early_stopping_rounds=50,\n","            verbose_eval=500)\n","\n","best_lgb_score = min(lgb_cv['rmse-mean'])\n","best_lgb_iteration = len(lgb_cv['rmse-mean'])\n","print (', best_score: %f, best_iteration: %d' % (best_lgb_score, best_lgb_iteration))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.01, 'num_leaves': 30, 'max_depth': 28, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 0.011020449786837139, 'feature_fraction': 0.3270532900734156, 'bagging_fraction': 0.9109777545232665, 'bagging_freq': 1, 'lambda_l2': 0.9573128272463252, 'lambda_l1': 0.3689738745120329, 'seed': 1234}\n","[500]\tcv_agg's rmse: 0.493133 + 0.00177316\n","[1000]\tcv_agg's rmse: 0.481575 + 0.00191599\n","[1500]\tcv_agg's rmse: 0.478809 + 0.00197259\n","[2000]\tcv_agg's rmse: 0.477861 + 0.0020071\n","[2500]\tcv_agg's rmse: 0.477321 + 0.00201479\n","[3000]\tcv_agg's rmse: 0.47692 + 0.00199175\n","[3500]\tcv_agg's rmse: 0.476625 + 0.00198271\n","[4000]\tcv_agg's rmse: 0.476381 + 0.00198176\n","[4500]\tcv_agg's rmse: 0.47618 + 0.00198871\n","[5000]\tcv_agg's rmse: 0.476015 + 0.00197781\n","[5500]\tcv_agg's rmse: 0.475884 + 0.00197172\n","[6000]\tcv_agg's rmse: 0.47577 + 0.00196483\n","[6500]\tcv_agg's rmse: 0.475701 + 0.00197308\n","[7000]\tcv_agg's rmse: 0.475635 + 0.00198708\n","[7500]\tcv_agg's rmse: 0.475591 + 0.00199642\n",", best_score: 0.475563, best_iteration: 7839\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lMNbrTDb24rn","colab_type":"code","colab":{}},"source":["from sklearn.metrics import mean_squared_error\n","\n","def lgb_rgr_stack(rgr_params, train_x, train_y, test_x, kfolds, early_stopping_rounds=0, train_y_dummy=None):\n","\n","    skf = KFold(n_splits=kfolds,random_state=1234)\n","    skf_ids = list(skf.split(train_y))\n","\n","\n","    train_blend_x = np.zeros((train_x.shape[0], len(rgr_params)))\n","    test_blend_x = np.zeros((test_x.shape[0], len(rgr_params)))\n","    blend_scores = np.zeros ((kfolds,len(rgr_params)))\n","\n","    print(\"Start stacking.\")\n","    for j, params in enumerate(rgr_params):\n","        print(\"Stacking model\",j+1, params)\n","        test_blend_x_j = np.zeros((test_x.shape[0]))\n","        for i, (train_ids, val_ids) in enumerate(skf_ids):\n","            start = time.time()\n","            print(\"Model %d fold %d\" %(j+1,i+1))\n","            train_x_fold = train_x[train_ids]\n","            train_y_fold = train_y[train_ids]\n","            val_x_fold = train_x[val_ids]\n","            val_y_fold = train_y[val_ids]\n","            print(i, params)\n","            \n","            \n","            if early_stopping_rounds==0:\n","                num_boost_round = copy.deepcopy(params['num_boost_round'])\n","                model = lgb.train(params,\n","                                    lgb.Dataset(train_x_fold, \n","                                                train_y_fold\n","                                               ),\n","                                  num_boost_round=num_boost_round,\n","                                  verbose_eval=500\n","                )\n","                val_y_predict_fold = model.predict(val_x_fold)\n","                score = np.sqrt(mean_squared_error(val_y_fold,val_y_predict_fold))\n","                print(\"Score for Model %d fold %d: %f \" % (j+1,i+1,score))\n","                blend_scores[i,j]=score\n","                train_blend_x[val_ids, j] = val_y_predict_fold\n","                test_blend_x_j = test_blend_x_j + model.predict(test_x)\n","                print(\"Model %d fold %d finished in %d seconds.\" % (j+1,i+1, time.time()-start))\n","            else:\n","                model = lgb.train(params,\n","                                    lgb.Dataset(train_x_fold, \n","                                                train_y_fold\n","                                               ),\n","                                  valid_sets=[lgb.Dataset(val_x_fold, \n","                                                val_y_fold\n","                                                         )],\n","                                  valid_names=['valid'],\n","                                  num_boost_round=10000000,\n","                                  early_stopping_rounds = early_stopping_rounds,\n","                                  verbose_eval=500\n","                                )\n","                best_iteration = model.best_iteration\n","                print(model.best_score['valid']['rmse'])\n","                val_y_predict_fold = model.predict(val_x_fold, num_iteration=best_iteration)\n","                score = np.sqrt(mean_squared_error(val_y_fold,val_y_predict_fold))\n","                print(\"Score for Model %d fold %d: %f \" % (j+1,i+1,score))\n","                blend_scores[i,j]=score\n","                train_blend_x[val_ids, j] = val_y_predict_fold\n","                test_blend_x_j = test_blend_x_j + model.predict(test_x, num_iteration=best_iteration)\n","                print(\"Model %d fold %d finished in %d seconds.\" % (j+1,i+1, time.time()-start))                \n","                \n","        test_blend_x[:,j] = test_blend_x_j/kfolds\n","        print(\"Score for model %d is %f\" % (j+1,np.mean(blend_scores[:,j])))\n","    return train_blend_x, test_blend_x, blend_scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKiQHT7b6ngM","colab_type":"code","outputId":"cc93fce4-aa8f-4a8e-bf4a-855ada668e04","executionInfo":{"status":"ok","timestamp":1585932373030,"user_tz":240,"elapsed":374,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["lgb_params = []\n","## Top 5 auto-tuned parameters\n","for i in range(4):\n","    params=dict()\n","    params['num_leaves'] = int(lgb_BO_scores['num_leaves'][i])\n","    params['max_depth'] = int(lgb_BO_scores['max_depth'][i])\n","    params['min_sum_hessian_in_leaf'] = int(lgb_BO_scores['min_sum_hessian_in_leaf'][i])\n","    params['min_gain_to_split'] = lgb_BO_scores['min_gain_to_split'][i]\n","    params['feature_fraction'] = lgb_BO_scores['feature_fraction'][i]\n","    params['bagging_fraction'] = lgb_BO_scores['bagging_fraction'][i]\n","    params['bagging_freq'] = 1\n","    params['lambda_l2'] = lgb_BO_scores['lambda_l2'][i]\n","    params['lambda_l1'] = int(lgb_BO_scores['lambda_l1'][i])\n","    params['objective'] = 'regression'\n","    params['learning_rate'] = 0.05\n","    params['num_boost_round']=best_lgb_iteration\n","    params['seed'] = 1234\n","    params[\"metric\"] = 'rmse'\n","    lgb_params.append(params)\n","\n","## Best manual-tuned parameters\n","lgb_params.append(best_lgb_params)    \n","print(lgb_params)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[{'num_leaves': 19, 'max_depth': 13, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 1.8911939074101998, 'feature_fraction': 0.3935702090101798, 'bagging_fraction': 0.9260923095895497, 'bagging_freq': 1, 'lambda_l2': 0.5011725532537579, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}, {'num_leaves': 9, 'max_depth': 28, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 0.9987831566693989, 'feature_fraction': 0.5601058341275948, 'bagging_fraction': 0.9076850501904176, 'bagging_freq': 1, 'lambda_l2': 0.5944451062263593, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}, {'num_leaves': 11, 'max_depth': 22, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 2.7187828562922918, 'feature_fraction': 0.5678090432745226, 'bagging_fraction': 0.9452547287748738, 'bagging_freq': 1, 'lambda_l2': 0.6542431114025132, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}, {'num_leaves': 12, 'max_depth': 9, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 2.5886484059601296, 'feature_fraction': 0.323572271570093, 'bagging_fraction': 0.9653709218402505, 'bagging_freq': 1, 'lambda_l2': 0.9528651763800765, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}, {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"opOW1TDI6ylI","colab_type":"code","outputId":"55fc4b0a-2d51-46d9-953a-886fd15fe6ca","executionInfo":{"status":"ok","timestamp":1585933259538,"user_tz":240,"elapsed":362694,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_blend_x_lgb_ohe, test_blend_x_lgb_ohe, blend_scores_lgb_ohe = lgb_rgr_stack(lgb_params, train_x, train_y, test_x, 4, early_stopping_rounds=50)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n","/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Start stacking.\n","Stacking model 1 {'num_leaves': 19, 'max_depth': 13, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 1.8911939074101998, 'feature_fraction': 0.3935702090101798, 'bagging_fraction': 0.9260923095895497, 'bagging_freq': 1, 'lambda_l2': 0.5011725532537579, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n","Model 1 fold 1\n","0 {'num_leaves': 19, 'max_depth': 13, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 1.8911939074101998, 'feature_fraction': 0.3935702090101798, 'bagging_fraction': 0.9260923095895497, 'bagging_freq': 1, 'lambda_l2': 0.5011725532537579, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n","Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[399]\tvalid's rmse: 0.483283\n","0.48328311524900386\n","Score for Model 1 fold 1: 0.483283 \n","Model 1 fold 1 finished in 14 seconds.\n","Model 1 fold 2\n","1 {'num_leaves': 19, 'max_depth': 13, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 1.8911939074101998, 'feature_fraction': 0.3935702090101798, 'bagging_fraction': 0.9260923095895497, 'bagging_freq': 1, 'lambda_l2': 0.5011725532537579, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[438]\tvalid's rmse: 0.482828\n","0.4828275781401167\n","Score for Model 1 fold 2: 0.482828 \n","Model 1 fold 2 finished in 14 seconds.\n","Model 1 fold 3\n","2 {'num_leaves': 19, 'max_depth': 13, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 1.8911939074101998, 'feature_fraction': 0.3935702090101798, 'bagging_fraction': 0.9260923095895497, 'bagging_freq': 1, 'lambda_l2': 0.5011725532537579, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[405]\tvalid's rmse: 0.484792\n","0.48479184455217617\n","Score for Model 1 fold 3: 0.484792 \n","Model 1 fold 3 finished in 14 seconds.\n","Model 1 fold 4\n","3 {'num_leaves': 19, 'max_depth': 13, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 1.8911939074101998, 'feature_fraction': 0.3935702090101798, 'bagging_fraction': 0.9260923095895497, 'bagging_freq': 1, 'lambda_l2': 0.5011725532537579, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[379]\tvalid's rmse: 0.483479\n","0.4834790339567911\n","Score for Model 1 fold 4: 0.483479 \n","Model 1 fold 4 finished in 13 seconds.\n","Score for model 1 is 0.483595\n","Stacking model 2 {'num_leaves': 9, 'max_depth': 28, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 0.9987831566693989, 'feature_fraction': 0.5601058341275948, 'bagging_fraction': 0.9076850501904176, 'bagging_freq': 1, 'lambda_l2': 0.5944451062263593, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n","Model 2 fold 1\n","0 {'num_leaves': 9, 'max_depth': 28, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 0.9987831566693989, 'feature_fraction': 0.5601058341275948, 'bagging_fraction': 0.9076850501904176, 'bagging_freq': 1, 'lambda_l2': 0.5944451062263593, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.484981\n","Early stopping, best iteration is:\n","[839]\tvalid's rmse: 0.483424\n","0.4834237561965046\n","Score for Model 2 fold 1: 0.483424 \n","Model 2 fold 1 finished in 25 seconds.\n","Model 2 fold 2\n","1 {'num_leaves': 9, 'max_depth': 28, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 0.9987831566693989, 'feature_fraction': 0.5601058341275948, 'bagging_fraction': 0.9076850501904176, 'bagging_freq': 1, 'lambda_l2': 0.5944451062263593, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.484044\n","Early stopping, best iteration is:\n","[845]\tvalid's rmse: 0.482364\n","0.48236382410703044\n","Score for Model 2 fold 2: 0.482364 \n","Model 2 fold 2 finished in 25 seconds.\n","Model 2 fold 3\n","2 {'num_leaves': 9, 'max_depth': 28, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 0.9987831566693989, 'feature_fraction': 0.5601058341275948, 'bagging_fraction': 0.9076850501904176, 'bagging_freq': 1, 'lambda_l2': 0.5944451062263593, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.48673\n","Early stopping, best iteration is:\n","[929]\tvalid's rmse: 0.484981\n","0.4849812257699335\n","Score for Model 2 fold 3: 0.484985 \n","Model 2 fold 3 finished in 27 seconds.\n","Model 2 fold 4\n","3 {'num_leaves': 9, 'max_depth': 28, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 0.9987831566693989, 'feature_fraction': 0.5601058341275948, 'bagging_fraction': 0.9076850501904176, 'bagging_freq': 1, 'lambda_l2': 0.5944451062263593, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.485306\n","Early stopping, best iteration is:\n","[872]\tvalid's rmse: 0.483604\n","0.483603970836604\n","Score for Model 2 fold 4: 0.483604 \n","Model 2 fold 4 finished in 25 seconds.\n","Score for model 2 is 0.483594\n","Stacking model 3 {'num_leaves': 11, 'max_depth': 22, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 2.7187828562922918, 'feature_fraction': 0.5678090432745226, 'bagging_fraction': 0.9452547287748738, 'bagging_freq': 1, 'lambda_l2': 0.6542431114025132, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n","Model 3 fold 1\n","0 {'num_leaves': 11, 'max_depth': 22, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 2.7187828562922918, 'feature_fraction': 0.5678090432745226, 'bagging_fraction': 0.9452547287748738, 'bagging_freq': 1, 'lambda_l2': 0.6542431114025132, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[386]\tvalid's rmse: 0.486391\n","0.4863906242021359\n","Score for Model 3 fold 1: 0.486391 \n","Model 3 fold 1 finished in 14 seconds.\n","Model 3 fold 2\n","1 {'num_leaves': 11, 'max_depth': 22, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 2.7187828562922918, 'feature_fraction': 0.5678090432745226, 'bagging_fraction': 0.9452547287748738, 'bagging_freq': 1, 'lambda_l2': 0.6542431114025132, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[423]\tvalid's rmse: 0.485635\n","0.4856354514600897\n","Score for Model 3 fold 2: 0.485635 \n","Model 3 fold 2 finished in 15 seconds.\n","Model 3 fold 3\n","2 {'num_leaves': 11, 'max_depth': 22, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 2.7187828562922918, 'feature_fraction': 0.5678090432745226, 'bagging_fraction': 0.9452547287748738, 'bagging_freq': 1, 'lambda_l2': 0.6542431114025132, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[403]\tvalid's rmse: 0.487713\n","0.4877130319343863\n","Score for Model 3 fold 3: 0.487713 \n","Model 3 fold 3 finished in 15 seconds.\n","Model 3 fold 4\n","3 {'num_leaves': 11, 'max_depth': 22, 'min_sum_hessian_in_leaf': 0, 'min_gain_to_split': 2.7187828562922918, 'feature_fraction': 0.5678090432745226, 'bagging_fraction': 0.9452547287748738, 'bagging_freq': 1, 'lambda_l2': 0.6542431114025132, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[422]\tvalid's rmse: 0.486264\n","0.48626412074104153\n","Score for Model 3 fold 4: 0.486264 \n","Model 3 fold 4 finished in 15 seconds.\n","Score for model 3 is 0.486501\n","Stacking model 4 {'num_leaves': 12, 'max_depth': 9, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 2.5886484059601296, 'feature_fraction': 0.323572271570093, 'bagging_fraction': 0.9653709218402505, 'bagging_freq': 1, 'lambda_l2': 0.9528651763800765, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n","Model 4 fold 1\n","0 {'num_leaves': 12, 'max_depth': 9, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 2.5886484059601296, 'feature_fraction': 0.323572271570093, 'bagging_fraction': 0.9653709218402505, 'bagging_freq': 1, 'lambda_l2': 0.9528651763800765, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.485474\n","Early stopping, best iteration is:\n","[456]\tvalid's rmse: 0.485474\n","0.4854740643104017\n","Score for Model 4 fold 1: 0.485474 \n","Model 4 fold 1 finished in 13 seconds.\n","Model 4 fold 2\n","1 {'num_leaves': 12, 'max_depth': 9, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 2.5886484059601296, 'feature_fraction': 0.323572271570093, 'bagging_fraction': 0.9653709218402505, 'bagging_freq': 1, 'lambda_l2': 0.9528651763800765, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.485709\n","Early stopping, best iteration is:\n","[459]\tvalid's rmse: 0.485709\n","0.4857091216320995\n","Score for Model 4 fold 2: 0.485709 \n","Model 4 fold 2 finished in 13 seconds.\n","Model 4 fold 3\n","2 {'num_leaves': 12, 'max_depth': 9, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 2.5886484059601296, 'feature_fraction': 0.323572271570093, 'bagging_fraction': 0.9653709218402505, 'bagging_freq': 1, 'lambda_l2': 0.9528651763800765, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[418]\tvalid's rmse: 0.487494\n","0.4874938076624037\n","Score for Model 4 fold 3: 0.487494 \n","Model 4 fold 3 finished in 13 seconds.\n","Model 4 fold 4\n","3 {'num_leaves': 12, 'max_depth': 9, 'min_sum_hessian_in_leaf': 1, 'min_gain_to_split': 2.5886484059601296, 'feature_fraction': 0.323572271570093, 'bagging_fraction': 0.9653709218402505, 'bagging_freq': 1, 'lambda_l2': 0.9528651763800765, 'lambda_l1': 0, 'objective': 'regression', 'learning_rate': 0.05, 'num_boost_round': 7839, 'seed': 1234, 'metric': 'rmse'}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[398]\tvalid's rmse: 0.486387\n","0.48638660438075376\n","Score for Model 4 fold 4: 0.486387 \n","Model 4 fold 4 finished in 12 seconds.\n","Score for model 4 is 0.486266\n","Stacking model 5 {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n","Model 5 fold 1\n","0 {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n","Training until validation scores don't improve for 50 rounds.\n","[500]\tvalid's rmse: 0.474339\n","Early stopping, best iteration is:\n","[492]\tvalid's rmse: 0.474304\n","0.4743036009610409\n","Score for Model 5 fold 1: 0.474304 \n","Model 5 fold 1 finished in 23 seconds.\n","Model 5 fold 2\n","1 {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n","Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[436]\tvalid's rmse: 0.475387\n","0.4753870540377252\n","Score for Model 5 fold 2: 0.475387 \n","Model 5 fold 2 finished in 21 seconds.\n","Model 5 fold 3\n","2 {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n","Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[414]\tvalid's rmse: 0.477461\n","0.4774613771401132\n","Score for Model 5 fold 3: 0.477461 \n","Model 5 fold 3 finished in 21 seconds.\n","Model 5 fold 4\n","3 {'learning_rate': 0.05, 'metric': 'rmse', 'bagging_freq': 1, 'seed': 1234, 'objective': 'regression', 'num_leaves': 127, 'max_depth': -1, 'min_gain_to_split': 0, 'feature_fraction': 0.3, 'bagging_fraction': 1, 'min_sum_hessian_in_leaf': 100, 'lambda_l2': 0.1, 'lambda_l1': 0}\n","Training until validation scores don't improve for 50 rounds.\n","Early stopping, best iteration is:\n","[435]\tvalid's rmse: 0.474789\n","0.47478907752039506\n","Score for Model 5 fold 4: 0.474789 \n","Model 5 fold 4 finished in 22 seconds.\n","Score for model 5 is 0.475485\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5R5MYa8L7KHC","colab_type":"code","outputId":"d892d730-80b8-43f5-97d5-24daf8ac0777","executionInfo":{"status":"ok","timestamp":1585933500123,"user_tz":240,"elapsed":2322,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print (np.mean(blend_scores_lgb_ohe,axis=0))\n","np.savetxt(\"/content/drive/My Drive/Kaggle_Allstate/data/train_blend_x_lgb_ohe.csv\",train_blend_x_lgb_ohe, delimiter=\",\")\n","np.savetxt(\"/content/drive/My Drive/Kaggle_Allstate/data/test_blend_x_lgb_ohe.csv\",test_blend_x_lgb_ohe, delimiter=\",\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.48359543 0.48359423 0.48650081 0.4862659  0.47548528]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rpX73ZfpALU9","colab_type":"code","outputId":"b74e7508-39dd-4e3d-cc34-ea711c94069b","executionInfo":{"status":"ok","timestamp":1585933513927,"user_tz":240,"elapsed":449,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["blend_scores_lgb_ohe"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.48328312, 0.48342376, 0.48639062, 0.48547406, 0.4743036 ],\n","       [0.48282758, 0.48236437, 0.48563545, 0.48570912, 0.47538705],\n","       [0.48479185, 0.48498484, 0.48771303, 0.48749381, 0.47746138],\n","       [0.48347917, 0.48360397, 0.48626412, 0.48638661, 0.47478908]])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"-LBDpEuuAPKm","colab_type":"code","outputId":"ea4df98e-09a9-4de3-bf28-7d01360c2319","executionInfo":{"status":"ok","timestamp":1585934092614,"user_tz":240,"elapsed":375,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(train_blend_x_lgb_ohe)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"gdHAk3D9A9sD","colab_type":"text"},"source":["## stacking"]},{"cell_type":"code","metadata":{"id":"Obk3M4CTA-6T","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import Ridge,ElasticNet, SGDRegressor\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.model_selection import GridSearchCV\n","from numpy import genfromtxt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtBHgxNZBgIr","colab_type":"code","colab":{}},"source":["train_blend_x_xgb_ohe  = genfromtxt(\"/content/drive/My Drive/Kaggle_Allstate/data/train_blend_x_xgb_ohe.csv\", delimiter=',')\n","test_blend_x_xgb_ohe  = genfromtxt(\"/content/drive/My Drive/Kaggle_Allstate/data/test_blend_x_xgb_ohe.csv\", delimiter=',')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNO8P6sXA_fj","colab_type":"code","outputId":"4cf6bb5d-59a0-4de5-e741-61e6713ec5c3","executionInfo":{"status":"ok","timestamp":1585933765215,"user_tz":240,"elapsed":434,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print  (\"stacking.\")\n","param_grid = {\n","    'alpha':[0,0.00001,0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,15,20,25,30,35,40,45,50,55,60,70,100]\n","              }"],"execution_count":0,"outputs":[{"output_type":"stream","text":["stacking.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kbAiT6bdBMhf","colab_type":"code","outputId":"cd658036-017b-4c2b-e922-2b796d75708d","executionInfo":{"status":"ok","timestamp":1585934206877,"user_tz":240,"elapsed":3952,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = search_model(np.hstack((train_blend_x_xgb_ohe,\n","                                train_blend_x_lgb_ohe,\n","                                ))\n","                                , train_y\n","                                , Ridge()\n","                                , param_grid\n","                                , n_jobs=1\n","                                , cv=4\n","                                , refit=True)   \n","\n","print(\"best subsample:\", model.best_params_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting 4 folds for each of 26 candidates, totalling 104 fits\n","[CV] alpha=0 .........................................................\n","[CV] ......................... alpha=0, score=-1132.545, total=   0.1s\n","[CV] alpha=0 .........................................................\n","[CV] ......................... alpha=0, score=-1196.459, total=   0.1s\n","[CV] alpha=0 .........................................................\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[CV] ......................... alpha=0, score=-1133.522, total=   0.1s\n","[CV] alpha=0 .........................................................\n","[CV] ......................... alpha=0, score=-1211.354, total=   0.1s\n","[CV] alpha=1e-05 .....................................................\n","[CV] ..................... alpha=1e-05, score=-1131.808, total=   0.0s\n","[CV] alpha=1e-05 .....................................................\n","[CV] ..................... alpha=1e-05, score=-1138.928, total=   0.0s\n","[CV] alpha=1e-05 .....................................................\n","[CV] ..................... alpha=1e-05, score=-1133.556, total=   0.0s\n","[CV] alpha=1e-05 .....................................................\n","[CV] ..................... alpha=1e-05, score=-1130.855, total=   0.0s\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.4s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.4s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[CV] alpha=3e-05 .....................................................\n","[CV] ..................... alpha=3e-05, score=-1131.808, total=   0.0s\n","[CV] alpha=3e-05 .....................................................\n","[CV] ..................... alpha=3e-05, score=-1138.928, total=   0.0s\n","[CV] alpha=3e-05 .....................................................\n","[CV] ..................... alpha=3e-05, score=-1133.556, total=   0.0s\n","[CV] alpha=3e-05 .....................................................\n","[CV] ..................... alpha=3e-05, score=-1130.855, total=   0.0s\n","[CV] alpha=0.0001 ....................................................\n","[CV] .................... alpha=0.0001, score=-1131.808, total=   0.0s\n","[CV] alpha=0.0001 ....................................................\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.5s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.5s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[CV] .................... alpha=0.0001, score=-1138.928, total=   0.0s\n","[CV] alpha=0.0001 ....................................................\n","[CV] .................... alpha=0.0001, score=-1133.556, total=   0.0s\n","[CV] alpha=0.0001 ....................................................\n","[CV] .................... alpha=0.0001, score=-1130.855, total=   0.0s\n","[CV] alpha=0.0003 ....................................................\n","[CV] .................... alpha=0.0003, score=-1131.808, total=   0.0s\n","[CV] alpha=0.0003 ....................................................\n","[CV] .................... alpha=0.0003, score=-1138.928, total=   0.0s\n","[CV] alpha=0.0003 ....................................................\n","[CV] .................... alpha=0.0003, score=-1133.556, total=   0.0s\n","[CV] alpha=0.0003 ....................................................\n","[CV] .................... alpha=0.0003, score=-1130.855, total=   0.0s\n","[CV] alpha=0.001 .....................................................\n","[CV] ..................... alpha=0.001, score=-1131.808, total=   0.0s\n","[CV] alpha=0.001 .....................................................\n","[CV] ..................... alpha=0.001, score=-1138.928, total=   0.0s\n","[CV] alpha=0.001 .....................................................\n","[CV] ..................... alpha=0.001, score=-1133.556, total=   0.0s\n","[CV] alpha=0.001 .....................................................\n","[CV] ..................... alpha=0.001, score=-1130.855, total=   0.0s\n","[CV] alpha=0.003 .....................................................\n","[CV] ..................... alpha=0.003, score=-1131.808, total=   0.0s\n","[CV] alpha=0.003 .....................................................\n","[CV] ..................... alpha=0.003, score=-1138.928, total=   0.0s\n","[CV] alpha=0.003 .....................................................\n","[CV] ..................... alpha=0.003, score=-1133.556, total=   0.0s\n","[CV] alpha=0.003 .....................................................\n","[CV] ..................... alpha=0.003, score=-1130.855, total=   0.0s\n","[CV] alpha=0.01 ......................................................\n","[CV] ...................... alpha=0.01, score=-1131.808, total=   0.0s\n","[CV] alpha=0.01 ......................................................\n","[CV] ...................... alpha=0.01, score=-1138.928, total=   0.0s\n","[CV] alpha=0.01 ......................................................\n","[CV] ...................... alpha=0.01, score=-1133.556, total=   0.0s\n","[CV] alpha=0.01 ......................................................\n","[CV] ...................... alpha=0.01, score=-1130.855, total=   0.0s\n","[CV] alpha=0.03 ......................................................\n","[CV] ...................... alpha=0.03, score=-1131.808, total=   0.0s\n","[CV] alpha=0.03 ......................................................\n","[CV] ...................... alpha=0.03, score=-1138.928, total=   0.0s\n","[CV] alpha=0.03 ......................................................\n","[CV] ...................... alpha=0.03, score=-1133.556, total=   0.0s\n","[CV] alpha=0.03 ......................................................\n","[CV] ...................... alpha=0.03, score=-1130.855, total=   0.0s\n","[CV] alpha=0.1 .......................................................\n","[CV] ....................... alpha=0.1, score=-1131.808, total=   0.0s\n","[CV] alpha=0.1 .......................................................\n","[CV] ....................... alpha=0.1, score=-1138.928, total=   0.0s\n","[CV] alpha=0.1 .......................................................\n","[CV] ....................... alpha=0.1, score=-1133.556, total=   0.0s\n","[CV] alpha=0.1 .......................................................\n","[CV] ....................... alpha=0.1, score=-1130.855, total=   0.0s\n","[CV] alpha=0.3 .......................................................\n","[CV] ....................... alpha=0.3, score=-1131.807, total=   0.0s\n","[CV] alpha=0.3 .......................................................\n","[CV] ....................... alpha=0.3, score=-1138.928, total=   0.0s\n","[CV] alpha=0.3 .......................................................\n","[CV] ....................... alpha=0.3, score=-1133.556, total=   0.0s\n","[CV] alpha=0.3 .......................................................\n","[CV] ....................... alpha=0.3, score=-1130.855, total=   0.0s\n","[CV] alpha=1 .........................................................\n","[CV] ......................... alpha=1, score=-1131.806, total=   0.0s\n","[CV] alpha=1 .........................................................\n","[CV] ......................... alpha=1, score=-1138.928, total=   0.0s\n","[CV] alpha=1 .........................................................\n","[CV] ......................... alpha=1, score=-1133.554, total=   0.0s\n","[CV] alpha=1 .........................................................\n","[CV] ......................... alpha=1, score=-1130.857, total=   0.0s\n","[CV] alpha=3 .........................................................\n","[CV] ......................... alpha=3, score=-1131.804, total=   0.0s\n","[CV] alpha=3 .........................................................\n","[CV] ......................... alpha=3, score=-1138.927, total=   0.0s\n","[CV] alpha=3 .........................................................\n","[CV] ......................... alpha=3, score=-1133.548, total=   0.0s\n","[CV] alpha=3 .........................................................\n","[CV] ......................... alpha=3, score=-1130.862, total=   0.0s\n","[CV] alpha=10 ........................................................\n","[CV] ........................ alpha=10, score=-1131.796, total=   0.0s\n","[CV] alpha=10 ........................................................\n","[CV] ........................ alpha=10, score=-1138.926, total=   0.0s\n","[CV] alpha=10 ........................................................\n","[CV] ........................ alpha=10, score=-1133.531, total=   0.0s\n","[CV] alpha=10 ........................................................\n","[CV] ........................ alpha=10, score=-1130.879, total=   0.0s\n","[CV] alpha=15 ........................................................\n","[CV] ........................ alpha=15, score=-1131.792, total=   0.0s\n","[CV] alpha=15 ........................................................\n","[CV] ........................ alpha=15, score=-1138.926, total=   0.0s\n","[CV] alpha=15 ........................................................\n","[CV] ........................ alpha=15, score=-1133.520, total=   0.0s\n","[CV] alpha=15 ........................................................\n","[CV] ........................ alpha=15, score=-1130.892, total=   0.0s\n","[CV] alpha=20 ........................................................\n","[CV] ........................ alpha=20, score=-1131.789, total=   0.0s\n","[CV] alpha=20 ........................................................\n","[CV] ........................ alpha=20, score=-1138.925, total=   0.0s\n","[CV] alpha=20 ........................................................\n","[CV] ........................ alpha=20, score=-1133.510, total=   0.0s\n","[CV] alpha=20 ........................................................\n","[CV] ........................ alpha=20, score=-1130.905, total=   0.0s\n","[CV] alpha=25 ........................................................\n","[CV] ........................ alpha=25, score=-1131.786, total=   0.0s\n","[CV] alpha=25 ........................................................\n","[CV] ........................ alpha=25, score=-1138.925, total=   0.0s\n","[CV] alpha=25 ........................................................\n","[CV] ........................ alpha=25, score=-1133.501, total=   0.0s\n","[CV] alpha=25 ........................................................\n","[CV] ........................ alpha=25, score=-1130.919, total=   0.0s\n","[CV] alpha=30 ........................................................\n","[CV] ........................ alpha=30, score=-1131.785, total=   0.0s\n","[CV] alpha=30 ........................................................\n","[CV] ........................ alpha=30, score=-1138.924, total=   0.0s\n","[CV] alpha=30 ........................................................\n","[CV] ........................ alpha=30, score=-1133.493, total=   0.0s\n","[CV] alpha=30 ........................................................\n","[CV] ........................ alpha=30, score=-1130.933, total=   0.0s\n","[CV] alpha=35 ........................................................\n","[CV] ........................ alpha=35, score=-1131.784, total=   0.0s\n","[CV] alpha=35 ........................................................\n","[CV] ........................ alpha=35, score=-1138.925, total=   0.0s\n","[CV] alpha=35 ........................................................\n","[CV] ........................ alpha=35, score=-1133.487, total=   0.0s\n","[CV] alpha=35 ........................................................\n","[CV] ........................ alpha=35, score=-1130.946, total=   0.0s\n","[CV] alpha=40 ........................................................\n","[CV] ........................ alpha=40, score=-1131.785, total=   0.0s\n","[CV] alpha=40 ........................................................\n","[CV] ........................ alpha=40, score=-1138.925, total=   0.0s\n","[CV] alpha=40 ........................................................\n","[CV] ........................ alpha=40, score=-1133.480, total=   0.0s\n","[CV] alpha=40 ........................................................\n","[CV] ........................ alpha=40, score=-1130.960, total=   0.0s\n","[CV] alpha=45 ........................................................\n","[CV] ........................ alpha=45, score=-1131.786, total=   0.0s\n","[CV] alpha=45 ........................................................\n","[CV] ........................ alpha=45, score=-1138.926, total=   0.0s\n","[CV] alpha=45 ........................................................\n","[CV] ........................ alpha=45, score=-1133.475, total=   0.0s\n","[CV] alpha=45 ........................................................\n","[CV] ........................ alpha=45, score=-1130.974, total=   0.0s\n","[CV] alpha=50 ........................................................\n","[CV] ........................ alpha=50, score=-1131.787, total=   0.0s\n","[CV] alpha=50 ........................................................\n","[CV] ........................ alpha=50, score=-1138.927, total=   0.0s\n","[CV] alpha=50 ........................................................\n","[CV] ........................ alpha=50, score=-1133.470, total=   0.0s\n","[CV] alpha=50 ........................................................\n","[CV] ........................ alpha=50, score=-1130.988, total=   0.0s\n","[CV] alpha=55 ........................................................\n","[CV] ........................ alpha=55, score=-1131.790, total=   0.0s\n","[CV] alpha=55 ........................................................\n","[CV] ........................ alpha=55, score=-1138.928, total=   0.0s\n","[CV] alpha=55 ........................................................\n","[CV] ........................ alpha=55, score=-1133.466, total=   0.0s\n","[CV] alpha=55 ........................................................\n","[CV] ........................ alpha=55, score=-1131.002, total=   0.0s\n","[CV] alpha=60 ........................................................\n","[CV] ........................ alpha=60, score=-1131.792, total=   0.0s\n","[CV] alpha=60 ........................................................\n","[CV] ........................ alpha=60, score=-1138.929, total=   0.0s\n","[CV] alpha=60 ........................................................\n","[CV] ........................ alpha=60, score=-1133.462, total=   0.0s\n","[CV] alpha=60 ........................................................\n","[CV] ........................ alpha=60, score=-1131.016, total=   0.0s\n","[CV] alpha=70 ........................................................\n","[CV] ........................ alpha=70, score=-1131.799, total=   0.0s\n","[CV] alpha=70 ........................................................\n","[CV] ........................ alpha=70, score=-1138.932, total=   0.0s\n","[CV] alpha=70 ........................................................\n","[CV] ........................ alpha=70, score=-1133.456, total=   0.0s\n","[CV] alpha=70 ........................................................\n","[CV] ........................ alpha=70, score=-1131.045, total=   0.0s\n","[CV] alpha=100 .......................................................\n","[CV] ....................... alpha=100, score=-1131.828, total=   0.0s\n","[CV] alpha=100 .......................................................\n","[CV] ....................... alpha=100, score=-1138.948, total=   0.0s\n","[CV] alpha=100 .......................................................\n","[CV] ....................... alpha=100, score=-1133.446, total=   0.0s\n","[CV] alpha=100 .......................................................\n","[CV] ....................... alpha=100, score=-1131.132, total=   0.0s\n","params:\n","\n","[{'alpha': 0}, {'alpha': 1e-05}, {'alpha': 3e-05}, {'alpha': 0.0001}, {'alpha': 0.0003}, {'alpha': 0.001}, {'alpha': 0.003}, {'alpha': 0.01}, {'alpha': 0.03}, {'alpha': 0.1}, {'alpha': 0.3}, {'alpha': 1}, {'alpha': 3}, {'alpha': 10}, {'alpha': 15}, {'alpha': 20}, {'alpha': 25}, {'alpha': 30}, {'alpha': 35}, {'alpha': 40}, {'alpha': 45}, {'alpha': 50}, {'alpha': 55}, {'alpha': 60}, {'alpha': 70}, {'alpha': 100}]\n","mean test scores:\n","\n","[-1168.47005799 -1133.78680259 -1133.78680258 -1133.78680254\n"," -1133.78680242 -1133.78680201 -1133.78680085 -1133.78679676\n"," -1133.7867851  -1133.78674439 -1133.78662983 -1133.78624167\n"," -1133.78531411 -1133.78317224 -1133.78243534 -1133.78226875\n"," -1133.78270599 -1133.78382017 -1133.78551005 -1133.7876842\n"," -1133.79020186 -1133.79315745 -1133.79647753 -1133.79995504\n"," -1133.80769085 -1133.83826049]\n","std test scores:\n","\n","[35.82741137  3.12259855  3.12259854  3.12259851  3.12259844  3.12259817\n","  3.1225974   3.12259471  3.12258702  3.1225601   3.12248296  3.12221356\n","  3.12137686  3.11834139  3.11598151  3.11349349  3.11082045  3.10791394\n","  3.10499715  3.10212061  3.09924173  3.09628876  3.09322964  3.09017223\n","  3.08421732  3.06699495]\n","Best score: -1133.782\n","Best parameters set: {'alpha': 20}\n","**********************************************\n","best subsample: {'alpha': 20}\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 104 out of 104 | elapsed:    3.6s finished\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n","  \"removed in 0.24.\", FutureWarning\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EEIpw_CPBVRv","colab_type":"code","outputId":"cdba5df7-fe98-4ff9-e821-408038e580ff","executionInfo":{"status":"ok","timestamp":1585934662987,"user_tz":240,"elapsed":36832,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["lgb_params = {'learning_rate': 0.05, 'metric': 'rmse',\n","              'bagging_freq': 1, 'seed': 1234, 'objective': 'regression',\n","              'num_leaves': 7, 'verbose': 1,\n","              'max_depth': 5, 'min_gain_to_split': 0,\n","              'feature_fraction': 0.1,\n","              'bagging_fraction': 0.9,\n","              'min_sum_hessian_in_leaf': 1,\n","              'lambda_l2': 0, 'lambda_l1': 0\n","              }\n","\n","train_blend_x = np.hstack((train_blend_x_xgb_ohe,\n","                            train_blend_x_lgb_ohe,\n","                            ))\n","\n","lgb_cv = lgb.cv(lgb_params,\n","                lgb.Dataset(train_blend_x,\n","                            label=train_y\n","                            ),\n","                num_boost_round=100000,\n","                nfold=kfolds,\n","                folds=skf.split(train_blend_x, train_y),\n","                early_stopping_rounds=50,\n","                verbose_eval=500)\n","\n","best_lgb_score = min(lgb_cv['rmse-mean'])\n","best_lgb_iteration = len(lgb_cv['rmse-mean'])\n","print(', best_score: %f, best_iteration: %d' %\n","      (best_lgb_score, best_lgb_iteration))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ERROR! Session/line number was not unique in database. History logging moved to new session 60\n","[500]\tcv_agg's rmse: 0.477395 + 0.00222046\n","[1000]\tcv_agg's rmse: 0.477158 + 0.00224431\n","[1500]\tcv_agg's rmse: 0.477019 + 0.00226803\n","[2000]\tcv_agg's rmse: 0.476926 + 0.00227664\n","[2500]\tcv_agg's rmse: 0.476859 + 0.00228916\n",", best_score: 0.476857, best_iteration: 2463\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oLM19QPjEZpE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mdDks8UuFB7t","colab_type":"text"},"source":["## submission "]},{"cell_type":"code","metadata":{"id":"xojyny0MFDbz","colab_type":"code","outputId":"53e07e30-f2ef-4834-f4cb-e309792ffc89","executionInfo":{"status":"ok","timestamp":1585934860005,"user_tz":240,"elapsed":763,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pred_y_ridge = np.exp(model.predict(np.hstack((\n","                                test_blend_x_xgb_ohe,\n","                                test_blend_x_lgb_ohe,\n",")))) - 200\n","\n","results = pd.DataFrame()\n","results['id'] = full_data[train_size:].id\n","results['loss'] = pred_y_ridge\n","results.to_csv(\"/content/drive/My Drive/Kaggle_Allstate/data/sub_ridge_blended.csv\", index=False)\n","print (\"Submission created.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Submission created.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eqf3_Qp6FVqu","colab_type":"code","outputId":"446ac27c-1493-48ac-fdbf-5c8eaa21f4b1","executionInfo":{"status":"ok","timestamp":1585935132346,"user_tz":240,"elapsed":15602,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_blend_x = np.hstack((test_blend_x_xgb_ohe,\n","                          test_blend_x_lgb_ohe,\n","                          ))\n","\n","model = lgb.train(lgb_params,\n","            lgb.Dataset(train_blend_x,\n","                        label=train_y\n","                        ),\n","            num_boost_round=best_lgb_iteration)\n","preds_lgb = np.expm1(model.predict(test_blend_x))\n","\n","results = pd.DataFrame()\n","results['id'] = full_data[train_size:].id\n","results['loss'] = preds_lgb\n","results.to_csv('/content/drive/My Drive/Kaggle_Allstate/data/sub_stacking_lgb.csv', index=False)\n","print (\"Submission created.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Submission created.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xV8OeBDvGQ7b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUseTT6nGSI8","colab_type":"text"},"source":["## Final submisstion "]},{"cell_type":"code","metadata":{"id":"YXIhX3UPGDG5","colab_type":"code","outputId":"f7c62119-98ff-49e2-e967-dac5305f4078","executionInfo":{"status":"ok","timestamp":1585935208238,"user_tz":240,"elapsed":767,"user":{"displayName":"Jianhua Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRbn9ZkeTJxpz2CFmh_qu7MwuV76FS7dBrlKsP=s64","userId":"16991759075772578229"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pred_y = pred_y_ridge*0.5 + preds_lgb*0.5\n","\n","results = pd.DataFrame()\n","results['id'] = full_data[train_size:].id\n","results['loss'] = pred_y\n","results.to_csv(\"/content/drive/My Drive/Kaggle_Allstate/data/sub_final.csv\", index=False)\n","print (\"Submission created.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Submission created.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S1DC_iu0Gsvf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}